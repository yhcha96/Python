{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP(DNN) -> 컴퓨터비전(이미지 처리)\n",
    "\n",
    "CNN(convolutional Neural Network)이 나오게 된 이유\n",
    "convolutional : 합성곱\n",
    "\n",
    "강아지 사진 분류기를 MLP로 만들었을 떄, 강아지 사진의 각도나 거리가 달라졌을때, 구분을 하지 못함.\n",
    "\n",
    "CNN을 이용하면 이미지에서 특징들을 추출해서 특징값을 input으로 함\n",
    "\n",
    "추출할 수 있는 특징 : 질감, 각도, 길이, 두께\n",
    "\n",
    "convolution layer \n",
    "- filter size를 결정해 정해진 stride 길이에 따라 이미지를 조각내어 인식\n",
    "입력데이터로부터 특징을 추출하는 역할을 수행하는 계층\n",
    "\n",
    "pooling layer(선택)\n",
    "- 특징의 대표값 추출 => 압축\n",
    "- 보편적으로 maxpooling 사용함\n",
    "\n",
    "\n",
    "flatten\n",
    "- 이미지로부터 다양한 특이점을 뽑아내고 이것을 1차원의 데이터로 변형\n",
    "\n",
    "필터 : 특징을 추출하는 기능\n",
    "활성화 함수 : 필터가 추출한 값을 비선형 값으로 변경\n",
    "\n",
    "\n",
    "스트라이드(strid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([[[[1],[2],[3]],\n",
    "                  [[4],[5],[6]],\n",
    "                  [[7],[8],[9]]]],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20efc751748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.reshape(3,-1), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(2), Dimension(1), Dimension(1)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱\n",
    "sess = tf.InteractiveSession() # eval\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding='VALID')\n",
    "conv2dImage = conv2d.eval() # 합성곱 연산 실행됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 2, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2dImage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,img in enumerate(conv2dImage):\n",
    "    print (img.reshape(2,-1))\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(img.reshape(2,-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 합성곱\n",
    "sess = tf.InteractiveSession() # eval\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding='SAME')\n",
    "conv2dImage = conv2d.eval() # 합성곱 연산 실행됨\n",
    "conv2dImage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,img in enumerate(conv2dImage):\n",
    "    print (img.reshape(3,-1))\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(img.reshape(3,-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-758d29429358>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터\n",
    "lr = 0.001\n",
    "epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Epoch: 0 Cost: 0.05319\n",
      "Epoch: 1 Cost: 0.05847\n",
      "Epoch: 2 Cost: 0.02295\n",
      "Epoch: 3 Cost: 0.03063\n",
      "Epoch: 4 Cost: 0.13124\n",
      "Epoch: 5 Cost: 0.03058\n",
      "Epoch: 6 Cost: 0.05531\n",
      "Epoch: 7 Cost: 0.01424\n",
      "Epoch: 8 Cost: 0.01037\n",
      "Epoch: 9 Cost: 0.02074\n",
      "Epoch: 10 Cost: 0.03563\n",
      "Epoch: 11 Cost: 0.01573\n",
      "Epoch: 12 Cost: 0.00284\n",
      "Epoch: 13 Cost: 0.02197\n",
      "Epoch: 14 Cost: 0.00114\n",
      "Accuracy: 0.9868999719619751\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "xImg = tf.reshape(x,[-1, 28, 28, 1]) # 2차원 -> 4차원\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# hidden\n",
    "w1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev = 0.01)) # (필터의 높이, 필터의 넓이, 채널 수, 필터의 개수) stddev=0.01주면 성능이 좋아짐\n",
    "L1 = tf.nn.conv2d(xImg,w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1) # relu사용하는 이유 : 미분하면 0아니면 1이 나오기 때문에\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1,2,2,1], padding='SAME')\n",
    "# conv ->(?,28,28,32)\n",
    "# relu ->(?,28,28,32)\n",
    "# pool ->(?,14,14,32)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev = 0.01))\n",
    "L2 = tf.nn.conv2d(L1, w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# conv ->(?, 14, 14, 64)\n",
    "# relu ->(?, 14, 14, 64)\n",
    "# pool ->(?, 7, 7, 32)\n",
    "\n",
    "# flaten\n",
    "L2_flat = tf.reshape(L2, [-1, 7*7*64])# flatening -> (?, 3136\n",
    "\n",
    "w3 = tf.get_variable(\"w3\",\n",
    "                     shape=[7*7*64, 10],\n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "hf = tf.matmul(L2_flat, w3)+b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hf, labels=y)) # logits= 예측, labels=정답\n",
    "opt = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):\n",
    "    avgCost=0\n",
    "    totalBatch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(totalBatch):\n",
    "        batchX, batchY = mnist.train.next_batch(batch_size)\n",
    "        cv,_ = sess.run([cost,opt], feed_dict={x:batchX, y:batchY})\n",
    "        avgCost += cv/totalBatch\n",
    "    print(\"Epoch: {} Cost: {:.5f}\".format(epoch, cv))\n",
    "    \n",
    "pred = tf.equal(tf.argmax(hf,1), tf.argmax(y,1))\n",
    "acc = tf.reduce_mean(tf.cast(pred,tf.float32))\n",
    "print(\"Accuracy: {}\".format(sess.run(acc, feed_dict={x:mnist.test.images, y:mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout 주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Cost: 0.17654\n",
      "Epoch: 1 Cost: 0.10907\n",
      "Epoch: 2 Cost: 0.08878\n",
      "Epoch: 3 Cost: 0.08440\n",
      "Epoch: 4 Cost: 0.05939\n",
      "Epoch: 5 Cost: 0.02649\n",
      "Epoch: 6 Cost: 0.08285\n",
      "Epoch: 7 Cost: 0.01205\n",
      "Epoch: 8 Cost: 0.02211\n",
      "Epoch: 9 Cost: 0.00793\n",
      "Epoch: 10 Cost: 0.02141\n",
      "Epoch: 11 Cost: 0.13593\n",
      "Epoch: 12 Cost: 0.01532\n",
      "Epoch: 13 Cost: 0.08017\n",
      "Epoch: 14 Cost: 0.20663\n",
      "Accuracy: 0.9902999997138977\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터\n",
    "lr = 0.001\n",
    "epochs = 15\n",
    "batch_size = 100\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "xImg = tf.reshape(x,[-1, 28, 28, 1]) # 2차원 -> 4차원\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# hidden\n",
    "w1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev = 0.01)) # (필터의 높이, 필터의 넓이, 채널 수, 필터의 개수) stddev=0.01주면 성능이 좋아짐\n",
    "L1 = tf.nn.conv2d(xImg,w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1) # relu사용하는 이유 : 미분하면 0아니면 1이 나오기 때문에\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1,2,2,1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "# conv ->(?,28,28,32)\n",
    "# relu ->(?,28,28,32)\n",
    "# pool ->(?,14,14,32)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev = 0.01))\n",
    "L2 = tf.nn.conv2d(L1, w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "# conv ->(?, 14, 14, 64)\n",
    "# relu ->(?, 14, 14, 64)\n",
    "# pool ->(?, 7, 7, 32)\n",
    "\n",
    "# flaten\n",
    "L2_flat = tf.reshape(L2, [-1, 7*7*64])# flatening -> (?, 3136\n",
    "\n",
    "w3 = tf.get_variable(\"w3\",\n",
    "                     shape=[7*7*64, 10],\n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "hf = tf.matmul(L2_flat, w3)+b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hf, labels=y)) # logits= 예측, labels=정답\n",
    "opt = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):\n",
    "    avgCost=0\n",
    "    totalBatch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(totalBatch):\n",
    "        batchX, batchY = mnist.train.next_batch(batch_size)\n",
    "        cv,_ = sess.run([cost,opt], feed_dict={x:batchX, y:batchY, keep_prob:0.7})\n",
    "        avgCost += cv/totalBatch\n",
    "    print(\"Epoch: {} Cost: {:.5f}\".format(epoch, cv))\n",
    "    \n",
    "pred = tf.equal(tf.argmax(hf,1), tf.argmax(y,1))\n",
    "acc = tf.reduce_mean(tf.cast(pred,tf.float32))\n",
    "print(\"Accuracy: {}\".format(sess.run(acc, feed_dict={x:mnist.test.images, y:mnist.test.labels, keep_prob:1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
