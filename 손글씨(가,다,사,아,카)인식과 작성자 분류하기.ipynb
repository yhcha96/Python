{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data 설명\n",
    " 18명의 '가','다','사','아','카' 손글씨\n",
    "- train data : 2세트\n",
    "- test data : 1세트\n",
    "\n",
    "size : 28*28\n",
    "\n",
    "파일명 : 글자_이름_세트번호_고유번호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. keras\n",
    " 1. 분류기 만들기\n",
    " 2. ImageDataGenerator 사용하여 이미지 증식 후 데이터 분류기 만들기\n",
    " 3. 작성자 분류기 만들기\n",
    "\n",
    "### 2. tensorflow\n",
    " 1. 분류기 만들기\n",
    " 2. ImageDataGenerator 사용하여 이미지 증식 후 데이터 분류기 만들기\n",
    " 3. 작성자 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(42)\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "# keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xTrain=[]\n",
    "# yTrain=[]\n",
    "# for i in range(180):\n",
    "#     x,y = train[i]\n",
    "#     xTrain.append(x)\n",
    "#     yTrain.append(y)\n",
    "    \n",
    "# xTest=[]\n",
    "# yTest=[]\n",
    "# for i in range(90):\n",
    "#     x,y = test[i]\n",
    "#     xTest.append(x)\n",
    "#     yTest.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xTrain = np.array(xTrain).reshape([180, 28, 28, 3])\n",
    "# xTest = np.array(xTest).reshape([90, 28, 28, 3])\n",
    "# yTrain = np.array(yTrain)\n",
    "# yTest = np.array(yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. keras\n",
    "## 1.1 이미지 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 images belonging to 5 classes.\n",
      "Found 90 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "imageDataGen = ImageDataGenerator(rescale = 1./255)\n",
    "train = imageDataGen.flow_from_directory(\"./data/img_data/handwriting/train\",\n",
    "                                        target_size = (28,28),\n",
    "                                        batch_size = 5,\n",
    "                                        class_mode = 'categorical')\n",
    "\n",
    "test = imageDataGen.flow_from_directory(\"./data/img_data/handwriting/test\",\n",
    "                                        target_size = (28,28),\n",
    "                                        batch_size = 5,\n",
    "                                        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 1.7093 - accuracy: 0.1467 - val_loss: 1.6266 - val_accuracy: 0.1200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.62664, saving model to ./CNNmodel/01-1.6266.hdf5\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.6218 - accuracy: 0.2133 - val_loss: 1.6063 - val_accuracy: 0.2400\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.62664 to 1.60634, saving model to ./CNNmodel/02-1.6063.hdf5\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 1.6167 - accuracy: 0.1200 - val_loss: 1.6097 - val_accuracy: 0.1600\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.60634\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 1.6099 - accuracy: 0.1467 - val_loss: 1.6138 - val_accuracy: 0.2400\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.60634\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 1.6106 - accuracy: 0.2000 - val_loss: 1.6121 - val_accuracy: 0.2400\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.60634\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 1.6119 - accuracy: 0.0933 - val_loss: 1.6136 - val_accuracy: 0.2800\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.60634\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 1s 95ms/step - loss: 1.6113 - accuracy: 0.1333 - val_loss: 1.6109 - val_accuracy: 0.0400\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.60634\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 2s 113ms/step - loss: 1.6103 - accuracy: 0.1867 - val_loss: 1.6089 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.60634\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 1.6116 - accuracy: 0.1467 - val_loss: 1.6049 - val_accuracy: 0.2800\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.60634 to 1.60492, saving model to ./CNNmodel/09-1.6049.hdf5\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 1s 93ms/step - loss: 1.6105 - accuracy: 0.2000 - val_loss: 1.6059 - val_accuracy: 0.1600\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.60492\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 2s 101ms/step - loss: 1.6091 - accuracy: 0.2133 - val_loss: 1.5587 - val_accuracy: 0.1600\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.60492 to 1.55874, saving model to ./CNNmodel/11-1.5587.hdf5\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 1.6203 - accuracy: 0.2133 - val_loss: 1.6033 - val_accuracy: 0.2800\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.55874\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 1.6116 - accuracy: 0.1600 - val_loss: 1.6023 - val_accuracy: 0.3200\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.55874\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.6048 - accuracy: 0.2533 - val_loss: 1.5313 - val_accuracy: 0.4400\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.55874 to 1.53135, saving model to ./CNNmodel/14-1.5313.hdf5\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.5855 - accuracy: 0.3733 - val_loss: 1.5149 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.53135 to 1.51495, saving model to ./CNNmodel/15-1.5149.hdf5\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 1s 91ms/step - loss: 1.5751 - accuracy: 0.3600 - val_loss: 1.5573 - val_accuracy: 0.3200\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.51495\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 2s 102ms/step - loss: 1.4687 - accuracy: 0.3867 - val_loss: 1.2039 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.51495 to 1.20392, saving model to ./CNNmodel/17-1.2039.hdf5\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 1s 91ms/step - loss: 1.3466 - accuracy: 0.4400 - val_loss: 1.2713 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.20392\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 1.1816 - accuracy: 0.4933 - val_loss: 0.6708 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.20392 to 0.67084, saving model to ./CNNmodel/19-0.6708.hdf5\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.0733 - accuracy: 0.6133 - val_loss: 1.7074 - val_accuracy: 0.5200\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.67084\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 1.0747 - accuracy: 0.4800 - val_loss: 1.7297 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.67084\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 1s 95ms/step - loss: 0.7853 - accuracy: 0.7067 - val_loss: 0.4689 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.67084 to 0.46888, saving model to ./CNNmodel/22-0.4689.hdf5\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.7257 - accuracy: 0.7333 - val_loss: 0.7054 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.46888\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 0.8198 - accuracy: 0.6933 - val_loss: 0.6922 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.46888\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 1s 93ms/step - loss: 0.6196 - accuracy: 0.8133 - val_loss: 0.8654 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.46888\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 0.6136 - accuracy: 0.7733 - val_loss: 0.7277 - val_accuracy: 0.7200\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.46888\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 2s 101ms/step - loss: 0.4561 - accuracy: 0.8667 - val_loss: 1.0781 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.46888\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 0.4990 - accuracy: 0.8133 - val_loss: 1.0716 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.46888\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 2s 101ms/step - loss: 0.5943 - accuracy: 0.8533 - val_loss: 3.5319 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.46888\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 0.3158 - accuracy: 0.9200 - val_loss: 0.0426 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.46888 to 0.04255, saving model to ./CNNmodel/30-0.0426.hdf5\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 0.4085 - accuracy: 0.8400 - val_loss: 0.4835 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.04255\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 0.2661 - accuracy: 0.8933 - val_loss: 0.3334 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04255\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 2s 102ms/step - loss: 0.4513 - accuracy: 0.7867 - val_loss: 0.4797 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04255\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 0.2627 - accuracy: 0.9067 - val_loss: 0.3273 - val_accuracy: 0.9600\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04255\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.3871 - accuracy: 0.8800 - val_loss: 4.0348 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04255\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 1s 93ms/step - loss: 0.3734 - accuracy: 0.8400 - val_loss: 4.4465 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04255\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 0.3679 - accuracy: 0.8667 - val_loss: 1.2670 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04255\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 0.4189 - accuracy: 0.8667 - val_loss: 0.6742 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04255\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.2549 - accuracy: 0.9067 - val_loss: 2.3097 - val_accuracy: 0.7200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04255\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 0.2051 - accuracy: 0.9600 - val_loss: 0.1103 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04255\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 0.2642 - accuracy: 0.8933 - val_loss: 0.3639 - val_accuracy: 0.7200\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04255\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.3536 - accuracy: 0.8800 - val_loss: 0.4836 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04255\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 2s 102ms/step - loss: 0.3454 - accuracy: 0.8533 - val_loss: 4.1376 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04255\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 0.2425 - accuracy: 0.9067 - val_loss: 0.9138 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04255\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 0.1795 - accuracy: 0.9467 - val_loss: 0.1711 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04255\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 0.1544 - accuracy: 0.9600 - val_loss: 0.0193 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.04255 to 0.01928, saving model to ./CNNmodel/46-0.0193.hdf5\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 0.2935 - accuracy: 0.8800 - val_loss: 3.2701 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.01928\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.1701 - accuracy: 0.9600 - val_loss: 0.0708 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.01928\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 0.2227 - accuracy: 0.9467 - val_loss: 0.1400 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.01928\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 2s 101ms/step - loss: 0.0890 - accuracy: 0.9867 - val_loss: 2.1693 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.01928\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.1644 - accuracy: 0.9333 - val_loss: 0.4015 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.01928\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 2s 102ms/step - loss: 0.1604 - accuracy: 0.9600 - val_loss: 0.5485 - val_accuracy: 0.7200\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.01928\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 0.2057 - accuracy: 0.9200 - val_loss: 0.4874 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.01928\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 0.1135 - accuracy: 0.9733 - val_loss: 0.0092 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.01928 to 0.00920, saving model to ./CNNmodel/54-0.0092.hdf5\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.1567 - accuracy: 0.9467 - val_loss: 2.9345 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00920\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 0.0923 - accuracy: 0.9733 - val_loss: 0.4127 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00920\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 0.1722 - accuracy: 0.9733 - val_loss: 0.0402 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00920\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 1s 94ms/step - loss: 0.1280 - accuracy: 0.9333 - val_loss: 0.0902 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00920\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 0.1429 - accuracy: 0.9467 - val_loss: 1.8348 - val_accuracy: 0.7200\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00920\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 0.0620 - accuracy: 0.9733 - val_loss: 0.1765 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00920\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 0.1063 - accuracy: 0.9600 - val_loss: 0.1467 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00920\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 0.0792 - accuracy: 0.9733 - val_loss: 0.3093 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00920\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 0.1151 - accuracy: 0.9467 - val_loss: 1.0973 - val_accuracy: 0.9600\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00920\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00920\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 0.1590 - accuracy: 0.9333 - val_loss: 0.1495 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00920\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 0.2020 - accuracy: 0.9200 - val_loss: 1.7343 - val_accuracy: 0.7200\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00920\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 0.5161 - accuracy: 0.8133 - val_loss: 4.5134 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00920\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 0.3494 - accuracy: 0.8400 - val_loss: 0.5087 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00920\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 1s 100ms/step - loss: 0.5093 - accuracy: 0.8133 - val_loss: 0.2708 - val_accuracy: 0.9600\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00920\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 2s 102ms/step - loss: 0.1864 - accuracy: 0.9333 - val_loss: 0.3935 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00920\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 0.1748 - accuracy: 0.9733 - val_loss: 0.3070 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00920\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 2s 101ms/step - loss: 0.1560 - accuracy: 0.9333 - val_loss: 0.4351 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00920\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 0.0574 - accuracy: 0.9733 - val_loss: 0.6567 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00920\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 0.1371 - accuracy: 1.0000 - val_loss: 3.3809 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00920\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.1357 - accuracy: 0.9600 - val_loss: 0.9283 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00920\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 2s 102ms/step - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00920\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 1s 95ms/step - loss: 0.0683 - accuracy: 0.9867 - val_loss: 0.1685 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00920\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 0.3687 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00920\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.1771 - accuracy: 0.9467 - val_loss: 4.5004e-04 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00920 to 0.00045, saving model to ./CNNmodel/79-0.0005.hdf5\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 0.0846 - accuracy: 0.9867 - val_loss: 1.5288 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00045\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 101ms/step - loss: 0.0741 - accuracy: 0.9867 - val_loss: 0.0033 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00045\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 0.1929 - accuracy: 0.9067 - val_loss: 1.4067 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00045\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 1s 94ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 3.0926 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00045\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 1s 100ms/step - loss: 0.1146 - accuracy: 0.9733 - val_loss: 5.4474 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00045\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 1s 93ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00045\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00045\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.0803 - accuracy: 0.9733 - val_loss: 0.5833 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00045\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 0.0575 - accuracy: 0.9867 - val_loss: 0.9219 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00045\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 0.0668 - accuracy: 0.9867 - val_loss: 0.0326 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00045\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 0.0890 - accuracy: 0.9600 - val_loss: 5.5273 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00045\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 0.0917 - accuracy: 0.9600 - val_loss: 0.7983 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00045\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 1s 93ms/step - loss: 0.1341 - accuracy: 0.9600 - val_loss: 0.2717 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00045\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 0.2745 - accuracy: 0.9467 - val_loss: 1.3163 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00045\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.6472 - accuracy: 0.8667 - val_loss: 0.1047 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00045\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 2s 101ms/step - loss: 0.5770 - accuracy: 0.8800 - val_loss: 0.0132 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00045\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 1s 94ms/step - loss: 0.1936 - accuracy: 0.9733 - val_loss: 2.1289 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00045\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00045\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 0.1186 - accuracy: 0.9600 - val_loss: 0.1839 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00045\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 1s 86ms/step - loss: 0.1150 - accuracy: 0.9733 - val_loss: 2.7410 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00045\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 0.0826 - accuracy: 0.9867 - val_loss: 0.0651 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00045\n"
     ]
    }
   ],
   "source": [
    "#모델 최적화()\n",
    "modelDir='./CNNmodel/' # '.' 현재 디렉토리를 의미. 현재 디렉토리 안에 myModel 디렉토리 생성하기 위해\n",
    "if not os.path.exists(modelDir): #만약 myModel 디렉토리가 존재하지 않는다면 # =>os 모듈이 필요했기에 import\n",
    "    os.mkdir(modelDir)\n",
    "modelPath=\"./CNNmodel/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = modelPath, monitor='val_loss', verbose=1,save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_loss', patience=32)\n",
    "\n",
    "# np.random.seed(42)\n",
    "hist = model.fit_generator(train,\n",
    "                   steps_per_epoch=15,\n",
    "                   epochs=100,\n",
    "                   validation_data=test,\n",
    "                   validation_steps=5,\n",
    "                   callbacks=[es,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "yLoss = hist.history['loss']\n",
    "yVloss = hist.history['val_loss']\n",
    "\n",
    "xLen = np.arange(len(yLoss))\n",
    "plt.plot(xLen,yVloss, marker='.',c='r',label='test_loss')\n",
    "plt.plot(xLen,yLoss, marker='.',c='b',label='train_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666746139526\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 ImageDataGenerator로 이미지 증식 후 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import array_to_img, img_to_array,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGen = ImageDataGenerator(rescale=1./255,\n",
    "                            rotation_range=15,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            shear_range=0.5,\n",
    "                            zoom_range=[0.8,2.0],\n",
    "                            horizontal_flip=True,\n",
    "                            vertical_flip=True,\n",
    "                            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 images belonging to 5 classes.\n",
      "Found 90 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1bc6c824b08>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgGen.flow_from_directory(\"./data/img_data/handwriting/train/\",\n",
    "                          target_size=(28,28),\n",
    "                          batch_size=5,\n",
    "                          class_mode='categorical')\n",
    "\n",
    "imgGen.flow_from_directory(\"./data/img_data/handwriting/test/\",\n",
    "                          target_size=(28,28),\n",
    "                          batch_size=5,\n",
    "                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 3 from 1 for 'conv2d_11/convolution' (op: 'Conv2D') with input shapes: [?,1,1,256], [3,3,256,128].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1606\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1607\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1608\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for 'conv2d_11/convolution' (op: 'Conv2D') with input shapes: [?,1,1,256], [3,3,256,128].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f21d9cd2b31c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[1;31m# Actually call the layer,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m   3715\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3716\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf_data_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3717\u001b[1;33m         **kwargs)\n\u001b[0m\u001b[0;32m   3718\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3719\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# NHWC -> NCHW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[1;34m(input, filter, padding, strides, dilation_rate, name, data_format, filters, dilations)\u001b[0m\n\u001b[0;32m    896\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m       name=name)\n\u001b[0m\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution)\u001b[0m\n\u001b[0;32m   1007\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1009\u001b[1;33m           name=name)\n\u001b[0m\u001b[0;32m   1010\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[0;32m   1072\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[0;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m       \u001b[1;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3355\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[1;32m-> 3357\u001b[1;33m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[0;32m   3358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3359\u001b[0m   def _create_op_internal(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3426\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3428\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1770\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1771\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1608\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for 'conv2d_11/convolution' (op: 'Conv2D') with input shapes: [?,1,1,256], [3,3,256,128]."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_corssentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "720\n",
      "36\n",
      "720\n",
      "36\n",
      "720\n",
      "36\n",
      "720\n",
      "36\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "images_name=[]\n",
    "folder_names=['aa','da','ga','ka','sa']\n",
    "for folder_name in folder_names:\n",
    "    folder_path = './data/img_data/handwriting/train/{}/*.jpg'.format(folder_name)\n",
    "    img_names = glob.glob(folder_path)\n",
    "    print(len(img_names))\n",
    "    c=0\n",
    "    for img_name in img_names:\n",
    "        img = load_img(img_name)\n",
    "        img = img_to_array(img)\n",
    "        img = img.reshape((1,)+img.shape)\n",
    "        \n",
    "        i = 0\n",
    "        for batch in imgGen.flow(img,\n",
    "                                 batch_size=1,\n",
    "                                 save_to_dir='./data/img_data/handwriting/train_plus/{}'.format(folder_name), # 저장 디렉토리\n",
    "                                 save_prefix=img_name[37:-4], # 저장 파일 이름 접두어\n",
    "                                 save_format='jpg'): # 저장 파일 확장자 지정\n",
    "            c+=1\n",
    "            i+=1\n",
    "            if i >=20:\n",
    "                break\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3774 images belonging to 5 classes.\n",
      "Found 90 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "imageDataGen = ImageDataGenerator(rescale = 1./255)\n",
    "train = imageDataGen.flow_from_directory(\"./data/img_data/handwriting/train_plus\",\n",
    "                                        target_size = (28,28),\n",
    "                                        batch_size = 3,\n",
    "                                        class_mode = 'categorical')\n",
    "\n",
    "test = imageDataGen.flow_from_directory(\"./data/img_data/handwriting/test\",\n",
    "                                        target_size = (28,28),\n",
    "                                        batch_size = 3,\n",
    "                                        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 1.9222 - accuracy: 0.1111 - val_loss: 1.5855 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.6371 - accuracy: 0.0833 - val_loss: 1.6120 - val_accuracy: 0.1778\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.6110 - accuracy: 0.2222 - val_loss: 1.6023 - val_accuracy: 0.2000\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.6049 - accuracy: 0.2222 - val_loss: 1.6043 - val_accuracy: 0.2111\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.6056 - accuracy: 0.2222 - val_loss: 1.5933 - val_accuracy: 0.2222\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 1.6350 - accuracy: 0.1389 - val_loss: 1.5930 - val_accuracy: 0.2000\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 1.6016 - accuracy: 0.2222 - val_loss: 1.6254 - val_accuracy: 0.2222\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.6340 - accuracy: 0.2778 - val_loss: 1.6048 - val_accuracy: 0.2000\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.6337 - accuracy: 0.2222 - val_loss: 1.6108 - val_accuracy: 0.2000\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 1.6126 - accuracy: 0.1389 - val_loss: 1.6088 - val_accuracy: 0.2000\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.6084 - accuracy: 0.2500 - val_loss: 1.6235 - val_accuracy: 0.2000\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 1.6167 - accuracy: 0.0556 - val_loss: 1.6156 - val_accuracy: 0.2000\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.6100 - accuracy: 0.1944 - val_loss: 1.6164 - val_accuracy: 0.2000\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.6114 - accuracy: 0.1667 - val_loss: 1.6069 - val_accuracy: 0.2000\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 1.6098 - accuracy: 0.2778 - val_loss: 1.6258 - val_accuracy: 0.2000\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.6090 - accuracy: 0.1944 - val_loss: 1.5997 - val_accuracy: 0.2111\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.6121 - accuracy: 0.1944 - val_loss: 1.6312 - val_accuracy: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b0095a8888>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=32)\n",
    "\n",
    "# np.random.seed(42)\n",
    "model.fit_generator(train,\n",
    "                    shuffle=False,\n",
    "                   steps_per_epoch=12,\n",
    "                   epochs=200,\n",
    "                   validation_data=test,)\n",
    "#                    validation_steps=6,\n",
    "#                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test, steps=6)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 작성자 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name=[]\n",
    "folder_names=['aa','da','ga','ka','sa']\n",
    "for folder_name in folder_names:\n",
    "    folder_path = './data/img_data/handwriting/train/{}/*.jpg'.format(folder_name)\n",
    "    img_names = glob.glob(folder_path)\n",
    "    images_name+=img_names\n",
    "    \n",
    "xTrain = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "for i in range(len(images_name)):\n",
    "    num = int(images_name[i][-6:-4])\n",
    "    \n",
    "    img = load_img(images_name[i])\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape((1,)+img.shape)\n",
    "    xTrain[num-1].append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = [[1]*10,[2]*10,[3]*10,[4]*10,[5]*10,[6]*10,[7]*10,[8]*10,[9]*10,[10]*10,[11]*10,[12]*10,[13]*10,[14]*10,[15]*10,[16]*10,[17]*10,[18]*10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name=[]\n",
    "folder_names=['aa','da','ga','ka','sa']\n",
    "for folder_name in folder_names:\n",
    "    folder_path = './data/img_data/handwriting/test/{}/*.jpg'.format(folder_name)\n",
    "    img_names = glob.glob(folder_path)\n",
    "    images_name+=img_names\n",
    "    \n",
    "xTest = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "for i in range(len(images_name)):\n",
    "    num = int(images_name[i][-6:-4])\n",
    "    \n",
    "    img = load_img(images_name[i])\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape((1,)+img.shape)\n",
    "    xTest[num-1].append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTest = [[1]*5,[2]*5,[3]*5,[4]*5,[5]*5,[6]*5,[7]*5,[8]*5,[9]*5,[10]*5,[11]*5,[12]*5,[13]*5,[14]*5,[15]*5,[16]*5,[17]*5,[18]*5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180, 28, 28, 3), (180, 18), (90, 28, 28, 3), (90, 18))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain = np.array(xTrain).reshape([180,28,28,3])\n",
    "xTest = np.array(xTest).reshape([90,28,28,3])\n",
    "yTrain = np.array(yTrain).reshape([180,])\n",
    "yTest = np.array(yTest).reshape([90,])\n",
    "\n",
    "yTrain = pd.DataFrame(yTrain.astype(str))\n",
    "yTrain = np.array(pd.get_dummies(yTrain))\n",
    "\n",
    "yTest = pd.DataFrame(yTest.astype(str))\n",
    "yTest = np.array(pd.get_dummies(yTest))\n",
    "\n",
    "\n",
    "\n",
    "xTrain.shape, yTrain.shape, xTest.shape, yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 90 samples\n",
      "Epoch 1/300\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 37.5826 - accuracy: 0.0722 - val_loss: 11.6440 - val_accuracy: 0.0556\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.00004\n",
      "Epoch 2/300\n",
      "180/180 [==============================] - 2s 14ms/step - loss: 11.4020 - accuracy: 0.0500 - val_loss: 3.4027 - val_accuracy: 0.0556\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00004\n",
      "Epoch 3/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 3.3837 - accuracy: 0.0389 - val_loss: 2.9114 - val_accuracy: 0.0889\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00004\n",
      "Epoch 4/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.9463 - accuracy: 0.0500 - val_loss: 2.8923 - val_accuracy: 0.0889\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00004\n",
      "Epoch 5/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.9301 - accuracy: 0.0722 - val_loss: 2.8649 - val_accuracy: 0.1222\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00004\n",
      "Epoch 6/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.8671 - accuracy: 0.0889 - val_loss: 2.8467 - val_accuracy: 0.1000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00004\n",
      "Epoch 7/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.8539 - accuracy: 0.0778 - val_loss: 2.8051 - val_accuracy: 0.1111\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00004\n",
      "Epoch 8/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.8124 - accuracy: 0.0889 - val_loss: 2.7262 - val_accuracy: 0.1333\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00004\n",
      "Epoch 9/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.7572 - accuracy: 0.1000 - val_loss: 2.6000 - val_accuracy: 0.0889\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00004\n",
      "Epoch 10/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.5927 - accuracy: 0.1222 - val_loss: 2.4156 - val_accuracy: 0.1444\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00004\n",
      "Epoch 11/300\n",
      "180/180 [==============================] - 2s 14ms/step - loss: 2.5079 - accuracy: 0.1944 - val_loss: 2.3731 - val_accuracy: 0.2556\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00004\n",
      "Epoch 12/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.4727 - accuracy: 0.1667 - val_loss: 2.2888 - val_accuracy: 0.3111\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00004\n",
      "Epoch 13/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 2.3543 - accuracy: 0.1889 - val_loss: 2.2125 - val_accuracy: 0.2333\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00004\n",
      "Epoch 14/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.2177 - accuracy: 0.2611 - val_loss: 2.2033 - val_accuracy: 0.2111\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00004\n",
      "Epoch 15/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.1367 - accuracy: 0.3000 - val_loss: 2.0597 - val_accuracy: 0.2556\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00004\n",
      "Epoch 16/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 2.2417 - accuracy: 0.2278 - val_loss: 2.1271 - val_accuracy: 0.2444\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00004\n",
      "Epoch 17/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.0412 - accuracy: 0.3111 - val_loss: 2.0282 - val_accuracy: 0.2778\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00004\n",
      "Epoch 18/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.0667 - accuracy: 0.3278 - val_loss: 2.0812 - val_accuracy: 0.2333\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00004\n",
      "Epoch 19/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 2.0072 - accuracy: 0.2889 - val_loss: 2.0971 - val_accuracy: 0.3222\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00004\n",
      "Epoch 20/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.9280 - accuracy: 0.3333 - val_loss: 1.9542 - val_accuracy: 0.3222\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00004\n",
      "Epoch 21/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.9717 - accuracy: 0.3278 - val_loss: 1.9832 - val_accuracy: 0.3444\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00004\n",
      "Epoch 22/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.8224 - accuracy: 0.3556 - val_loss: 2.0121 - val_accuracy: 0.3778\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00004\n",
      "Epoch 23/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 1.7160 - accuracy: 0.4000 - val_loss: 1.9828 - val_accuracy: 0.3444\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00004\n",
      "Epoch 24/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.6518 - accuracy: 0.4500 - val_loss: 1.8786 - val_accuracy: 0.3222\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00004\n",
      "Epoch 25/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.5842 - accuracy: 0.4611 - val_loss: 1.9410 - val_accuracy: 0.3667\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00004\n",
      "Epoch 26/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 1.7247 - accuracy: 0.4056 - val_loss: 2.2002 - val_accuracy: 0.3222\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00004\n",
      "Epoch 27/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.5705 - accuracy: 0.4611 - val_loss: 1.9280 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00004\n",
      "Epoch 28/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.5177 - accuracy: 0.4778 - val_loss: 1.9609 - val_accuracy: 0.3444\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00004\n",
      "Epoch 29/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.4322 - accuracy: 0.4778 - val_loss: 1.8578 - val_accuracy: 0.3556\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00004\n",
      "Epoch 30/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.3779 - accuracy: 0.4833 - val_loss: 2.0374 - val_accuracy: 0.4222\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00004\n",
      "Epoch 31/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.4176 - accuracy: 0.5056 - val_loss: 1.9586 - val_accuracy: 0.3778\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00004\n",
      "Epoch 32/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 1.4361 - accuracy: 0.4444 - val_loss: 2.1569 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00004\n",
      "Epoch 33/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.4204 - accuracy: 0.4944 - val_loss: 1.7742 - val_accuracy: 0.4333\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00004\n",
      "Epoch 34/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.5555 - accuracy: 0.4833 - val_loss: 1.7290 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00004\n",
      "Epoch 35/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 1.4735 - accuracy: 0.4611 - val_loss: 1.9674 - val_accuracy: 0.4222\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00004\n",
      "Epoch 36/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.4937 - accuracy: 0.4667 - val_loss: 1.7498 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00004\n",
      "Epoch 37/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.3793 - accuracy: 0.4944 - val_loss: 1.7806 - val_accuracy: 0.4333\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00004\n",
      "Epoch 38/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.4463 - accuracy: 0.5056 - val_loss: 1.6534 - val_accuracy: 0.5889\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00004\n",
      "Epoch 39/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.3047 - accuracy: 0.5056 - val_loss: 1.6861 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00004\n",
      "Epoch 40/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.2578 - accuracy: 0.5667 - val_loss: 1.6097 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00004\n",
      "Epoch 41/300\n",
      "180/180 [==============================] - 3s 14ms/step - loss: 1.2430 - accuracy: 0.5778 - val_loss: 1.9021 - val_accuracy: 0.4444\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00004\n",
      "Epoch 42/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 2s 13ms/step - loss: 1.2955 - accuracy: 0.5333 - val_loss: 1.6492 - val_accuracy: 0.4778\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00004\n",
      "Epoch 43/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.1209 - accuracy: 0.5778 - val_loss: 1.6897 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00004\n",
      "Epoch 44/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.0971 - accuracy: 0.6111 - val_loss: 1.8285 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00004\n",
      "Epoch 45/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.1107 - accuracy: 0.6278 - val_loss: 1.8153 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00004\n",
      "Epoch 46/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.0827 - accuracy: 0.6222 - val_loss: 1.8811 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00004\n",
      "Epoch 47/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.9727 - accuracy: 0.6278 - val_loss: 1.8081 - val_accuracy: 0.3889\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00004\n",
      "Epoch 48/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 1.0367 - accuracy: 0.6333 - val_loss: 1.6203 - val_accuracy: 0.5222\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00004\n",
      "Epoch 49/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.8901 - accuracy: 0.6556 - val_loss: 1.6598 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00004\n",
      "Epoch 50/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.9790 - accuracy: 0.6111 - val_loss: 1.6224 - val_accuracy: 0.5889\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00004\n",
      "Epoch 51/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.8707 - accuracy: 0.6556 - val_loss: 1.6819 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00004\n",
      "Epoch 52/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.8091 - accuracy: 0.6944 - val_loss: 2.0914 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00004\n",
      "Epoch 53/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.9091 - accuracy: 0.6556 - val_loss: 1.5584 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00004\n",
      "Epoch 54/300\n",
      "180/180 [==============================] - 3s 15ms/step - loss: 1.0269 - accuracy: 0.6556 - val_loss: 2.0135 - val_accuracy: 0.4667\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00004\n",
      "Epoch 55/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 1.0406 - accuracy: 0.6444 - val_loss: 2.1351 - val_accuracy: 0.4778\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00004\n",
      "Epoch 56/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.9007 - accuracy: 0.6778 - val_loss: 2.0826 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00004\n",
      "Epoch 57/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.8484 - accuracy: 0.7222 - val_loss: 1.9070 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00004\n",
      "Epoch 58/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.8919 - accuracy: 0.6722 - val_loss: 1.9482 - val_accuracy: 0.5444\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00004\n",
      "Epoch 59/300\n",
      "180/180 [==============================] - 2s 14ms/step - loss: 0.7547 - accuracy: 0.7333 - val_loss: 1.8398 - val_accuracy: 0.5444\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00004\n",
      "Epoch 60/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.7221 - accuracy: 0.7333 - val_loss: 1.6467 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00004\n",
      "Epoch 61/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.7678 - accuracy: 0.7167 - val_loss: 1.6434 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00004\n",
      "Epoch 62/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.6144 - accuracy: 0.8111 - val_loss: 1.6672 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00004\n",
      "Epoch 63/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.5940 - accuracy: 0.7889 - val_loss: 1.7375 - val_accuracy: 0.5889\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00004\n",
      "Epoch 64/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.5565 - accuracy: 0.8111 - val_loss: 1.6264 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00004\n",
      "Epoch 65/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.5647 - accuracy: 0.7889 - val_loss: 1.7949 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00004\n",
      "Epoch 66/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.6088 - accuracy: 0.7056 - val_loss: 1.7766 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00004\n",
      "Epoch 67/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.6147 - accuracy: 0.7667 - val_loss: 2.1391 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00004\n",
      "Epoch 68/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.7214 - accuracy: 0.7056 - val_loss: 2.3364 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00004\n",
      "Epoch 69/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.5783 - accuracy: 0.7556 - val_loss: 2.2369 - val_accuracy: 0.4778\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00004\n",
      "Epoch 70/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.6529 - accuracy: 0.7444 - val_loss: 1.6297 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00004\n",
      "Epoch 71/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.5268 - accuracy: 0.8056 - val_loss: 1.7851 - val_accuracy: 0.6111\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00004\n",
      "Epoch 72/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.5667 - accuracy: 0.7944 - val_loss: 2.1255 - val_accuracy: 0.5889\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00004\n",
      "Epoch 73/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.4819 - accuracy: 0.7722 - val_loss: 2.0062 - val_accuracy: 0.5444\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00004\n",
      "Epoch 74/300\n",
      "180/180 [==============================] - 2s 12ms/step - loss: 0.4430 - accuracy: 0.8444 - val_loss: 1.8344 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00004\n",
      "Epoch 75/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.3871 - accuracy: 0.8278 - val_loss: 2.0146 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00004\n",
      "Epoch 76/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.3331 - accuracy: 0.8722 - val_loss: 2.1781 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00004\n",
      "Epoch 77/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.3113 - accuracy: 0.8667 - val_loss: 2.2305 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00004\n",
      "Epoch 78/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.4504 - accuracy: 0.8500 - val_loss: 1.8804 - val_accuracy: 0.5889\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00004\n",
      "Epoch 79/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.4610 - accuracy: 0.8167 - val_loss: 1.8752 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00004\n",
      "Epoch 80/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.3972 - accuracy: 0.8389 - val_loss: 2.4316 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00004\n",
      "Epoch 81/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.4509 - accuracy: 0.8556 - val_loss: 2.3817 - val_accuracy: 0.5667\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00004\n",
      "Epoch 82/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.3368 - accuracy: 0.8722 - val_loss: 2.5911 - val_accuracy: 0.6111\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00004\n",
      "Epoch 83/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.3662 - accuracy: 0.8556 - val_loss: 3.1202 - val_accuracy: 0.5444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00004\n",
      "Epoch 84/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.3615 - accuracy: 0.8722 - val_loss: 2.6545 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00004\n",
      "Epoch 85/300\n",
      "180/180 [==============================] - 2s 13ms/step - loss: 0.4671 - accuracy: 0.8500 - val_loss: 2.6021 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x24a1ebf5408>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 최적화()\n",
    "modelDir='./CNNmodel/' # '.' 현재 디렉토리를 의미. 현재 디렉토리 안에 myModel 디렉토리 생성하기 위해\n",
    "if not os.path.exists(modelDir): #만약 myModel 디렉토리가 존재하지 않는다면 # =>os 모듈이 필요했기에 import\n",
    "    os.mkdir(modelDir)\n",
    "modelPath=\"./CNNmodel/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "es = EarlyStopping(monitor='val_loss', patience=32)\n",
    "\n",
    "model.fit(xTrain,yTrain,\n",
    "         batch_size=30, epochs=300,\n",
    "          validation_data=(xTest,yTest),\n",
    "         callbacks=[es,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.602080313364665, 0.6000000238418579]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xTest,yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tensorflow\n",
    "## 2.1 이미지 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 200\n",
    "batch_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 60 into shape (12,28,28,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e9602951500b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotalBatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mbatchX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mbatchY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatchX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatchY\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 60 into shape (12,28,28,3)"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 5])\n",
    "\n",
    "# hidden\n",
    "# (필터의 높이, 필터의 넓이, 채널 수, 필터의 개수)\n",
    "w1 = tf.Variable(tf.random_normal([5,5,1,32], stddev = 0.01))\n",
    "L1 = tf.nn.conv2d(x, w1, strides=[1,1,1,1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([3,3,1,64], stddev = 0.01))\n",
    "L2 = tf.nn.conv2d(L1, w2, strides=[1,1,1,1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "# flatten\n",
    "L2_flat = tf.reshape(L2, [-1, 7*7*64])\n",
    "\n",
    "w3 = tf.get_variable(\"w3\",\n",
    "                     shape=[7*7*64, 5],\n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([5]))\n",
    "hf = tf.matmul(L2_flat, w3)+b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hf, labels=y)) # logits= 예측, labels=정답\n",
    "opt = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):\n",
    "    avgCost=0\n",
    "    totalBatch = int(180/batch_size)\n",
    "    for i in range(1,totalBatch):\n",
    "        batchX = np.array(xTrain[(i-1)*batch_size:i*batch_size]).reshape([batch_size,28, 28, 3])\n",
    "        batchY = np.array(yTrain[(i-1)*batch_size:i*batch_size]).reshape([batch_size,28, 28, 3])\n",
    "        \n",
    "        cv,_ = sess.run([cost,opt], feed_dict={x:batchX, y:batchY})\n",
    "        avgCost += cv/totalBatch\n",
    "    print(\"Epoch: {} Cost: {:.5f}\".format(epoch, cv))\n",
    "    \n",
    "pred = tf.equal(tf.argmax(hf,1), tf.argmax(y,1))\n",
    "acc = tf.reduce_mean(tf.cast(pred,tf.float32))\n",
    "print(\"Accuracy: {}\".format(sess.run(acc, feed_dict={x:mnist.test.images, y:mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 ImageDataGenerator로 이미지 증식 후 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 작성자 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
