{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 분류\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-758d29429358>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None,784])\n",
    "y = tf.placeholder(tf.float32, [None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([784,10]))\n",
    "b = tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.nn.softmax(tf.matmul(x,w)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(hf), axis=1))\n",
    "ls = 0.1\n",
    "train = tf.train.GradientDescentOptimizer(ls).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "isCorrect = tf.equal(tf.argmax(hf,1), tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(isCorrect, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 몇번 실행\n",
    "numEpochs = 15\n",
    "batchSize = 100 # 100개씩 읽어서 train하겠다\n",
    "\n",
    "mnist.train.num_examples # train 이미지 개수\n",
    "numIter = mnist.train.num_examples / batchSize # numIter만큼하면 1 epoch가 끝난거\n",
    "numIter = int(numIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0001, cost: 2.826303\n",
      "Epoch:0002, cost: 1.061669\n",
      "Epoch:0003, cost: 0.838061\n",
      "Epoch:0004, cost: 0.733233\n",
      "Epoch:0005, cost: 0.669280\n",
      "Epoch:0006, cost: 0.624612\n",
      "Epoch:0007, cost: 0.591160\n",
      "Epoch:0008, cost: 0.563869\n",
      "Epoch:0009, cost: 0.541745\n",
      "Epoch:0010, cost: 0.522674\n",
      "Epoch:0011, cost: 0.506782\n",
      "Epoch:0012, cost: 0.492448\n",
      "Epoch:0013, cost: 0.479956\n",
      "Epoch:0014, cost: 0.468894\n",
      "Epoch:0015, cost: 0.458703\n",
      "정확도:  0.8951\n",
      "lable:  [9]\n",
      "predict:  [9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(numEpochs): # 15epoch만큼\n",
    "        avgCv = 0\n",
    "        for i in range(numIter): #\n",
    "            batchX,batchY = mnist.train.next_batch(batchSize) # ()안에 몇개씩 읽어올지(batchSize) 정해줄 수 있다\n",
    "            _,cv = sess.run([train, cost], feed_dict={x:batchX, y:batchY})\n",
    "            avgCv += cv/numIter\n",
    "        print(\"Epoch:{:04d}, cost:{:9f}\".format(epoch+1,avgCv))\n",
    "#         print(epoch+1, cv, avgCv)\n",
    "    print(\"정확도: \",accuracy.eval(session=sess, feed_dict={x:mnist.test.images, y:mnist.test.labels})) # test데이터로 확인\n",
    "    # mnist의 test데이터의 x는 mnist.test.image\n",
    "    # mnist의 test데이터의 y는 mnist.test.label\n",
    "    r = random.randint(0, mnist.test.num_examples-1)\n",
    "    print(\"lable: \", sess.run(tf.argmax(mnist.test.labels[r:r+1],1))) # r번째 이미지에 대한\n",
    "    print(\"predict: \",sess.run(tf.argmax(hf,1), feed_dict={x:mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28), cmap='Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras에서 학습 모델 저장/ 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다층 퍼셉트론 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련, 검증, 시험 데이터로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽어오기\n",
    "(xTrain, yTrain),(xTest,yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "(60000, 784) (60000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(xTrain.shape, yTrain.shape, xTest.shape, yTest.shape)\n",
    "xTrain = xTrain.reshape(-1,784).astype('float32')/255.0\n",
    "xTest = xTest.reshape(-1,784).astype('float32')/255.0\n",
    "print(xTrain.shape, yTrain.shape, xTest.shape, yTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = np_utils.to_categorical(yTrain)\n",
    "yTest = np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = int(xTrain.shape[0]*0.7)\n",
    "\n",
    "xVal = xTrain[num:]\n",
    "xTrain = xTrain[:num]\n",
    "yVal = yTrain[num:]\n",
    "yTrain = yTrain[:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64,input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학슴환경 설정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/15\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 1.0003 - accuracy: 0.7444 - val_loss: 0.5205 - val_accuracy: 0.8702\n",
      "Epoch 2/15\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.4540 - accuracy: 0.8806 - val_loss: 0.3925 - val_accuracy: 0.8926\n",
      "Epoch 3/15\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 0.3753 - accuracy: 0.8965 - val_loss: 0.3477 - val_accuracy: 0.9027\n",
      "Epoch 4/15\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 0.3393 - accuracy: 0.9045 - val_loss: 0.3233 - val_accuracy: 0.9099\n",
      "Epoch 5/15\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 0.3167 - accuracy: 0.9106 - val_loss: 0.3074 - val_accuracy: 0.9123\n",
      "Epoch 6/15\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 0.2993 - accuracy: 0.9149 - val_loss: 0.2925 - val_accuracy: 0.9176\n",
      "Epoch 7/15\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.2849 - accuracy: 0.9192 - val_loss: 0.2832 - val_accuracy: 0.9186\n",
      "Epoch 8/15\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 0.2726 - accuracy: 0.9221 - val_loss: 0.2744 - val_accuracy: 0.9229\n",
      "Epoch 9/15\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.2616 - accuracy: 0.9253 - val_loss: 0.2644 - val_accuracy: 0.9252\n",
      "Epoch 10/15\n",
      "42000/42000 [==============================] - 1s 31us/step - loss: 0.2517 - accuracy: 0.9290 - val_loss: 0.2562 - val_accuracy: 0.9268\n",
      "Epoch 11/15\n",
      "42000/42000 [==============================] - 1s 32us/step - loss: 0.2428 - accuracy: 0.9314 - val_loss: 0.2494 - val_accuracy: 0.9286\n",
      "Epoch 12/15\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 0.2347 - accuracy: 0.9338 - val_loss: 0.2418 - val_accuracy: 0.9316\n",
      "Epoch 13/15\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 0.2269 - accuracy: 0.9364 - val_loss: 0.2374 - val_accuracy: 0.9314\n",
      "Epoch 14/15\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.2199 - accuracy: 0.9384 - val_loss: 0.2301 - val_accuracy: 0.9340\n",
      "Epoch 15/15\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.2130 - accuracy: 0.9400 - val_loss: 0.2240 - val_accuracy: 0.9368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x145521c79c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xTrain,yTrain, epochs=15, batch_size=50, validation_data=(xVal,yVal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 12us/step\n",
      "평가결과:[0.21545489287702366, 0.9391000270843506]\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "metrics = model.evaluate(xTest,yTest,batch_size=50)\n",
    "print(\"평가결과:\"+str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(xTest.shape[0],5)\n",
    "xHat = xTest[idx]\n",
    "yHat = model.predict_classes(xHat) # 결과값을 classes로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: 8 실제값: 8\n",
      "예측값: 3 실제값: 3\n",
      "예측값: 6 실제값: 6\n",
      "예측값: 4 실제값: 4\n",
      "예측값: 8 실제값: 8\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"예측값: {} 실제값: {}\".format(yHat[i], np.argmax(yTest[idx[i]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "모델 : 모델 아키텍쳐와 모델 가중치로 구성\n",
    "모델 아키텍처 : 모델이 어떤 층으로 구성\n",
    "모델 가중치 : weight, bias\n",
    "\n",
    "save() : keras모델 저장 함수(아키텍쳐+가중치)\n",
    "파일 형식 : \"h5\"로 저장\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mnist.h5\")\n",
    "# 폴더에 mnist.h5 파일이 생성됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: 0 실제값: 0\n",
      "예측값: 2 실제값: 2\n",
      "예측값: 7 실제값: 7\n",
      "예측값: 0 실제값: 0\n",
      "예측값: 8 실제값: 8\n",
      "예측값: 2 실제값: 2\n",
      "예측값: 7 실제값: 5\n",
      "예측값: 9 실제값: 9\n",
      "예측값: 7 실제값: 7\n",
      "예측값: 7 실제값: 7\n"
     ]
    }
   ],
   "source": [
    "# data 불러오기\n",
    "(xTrain, yTrain),(xTest,yTest) = mnist.load_data()\n",
    "xTest = xTest.reshape(-1,784).astype('float32')/255.0\n",
    "yTest = np_utils.to_categorical(yTest)\n",
    "idx = np.random.choice(xTest.shape[0],10)\n",
    "xhat=xTest[idx]\n",
    "\n",
    "# 모델 불러오기\n",
    "from keras.models import load_model\n",
    "model = load_model('mnist.h5')\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"예측값: {} 실제값: {}\".format(yhat[i], np.argmax(yTest[idx[i]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아키텍처 시각화\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# \n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d1716ed67e43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m SVG(model_to_dot(model, show_shapes=True),\n\u001b[0m\u001b[0;32m      2\u001b[0m    create(prog='dot', format='svg'))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         raise OSError(\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[1;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[1;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True),\n",
    "   create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Param # : weight, bias 뜻함\n",
    "\n",
    "650 =  64*10 + 10\n",
    "\n",
    "50240 = 784*64 + 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 4), (8, 1))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata = xy[:,:-1]\n",
    "ydata = xy[:,[-1]]\n",
    "\n",
    "xdata.shape, ydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,4])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([4,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.matmul(x,w) +b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hf-y)) # regression\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(1e-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cv :  1935953600000.0\n",
      "hv :  [[ -980922.8]\n",
      " [-1974649.6]\n",
      " [-1553396. ]\n",
      " [-1088935.8]\n",
      " [-1283362. ]\n",
      " [-1294164.4]\n",
      " [-1186149.9]\n",
      " [-1510190. ]]\n",
      "2\n",
      "cv :  2.1269942e+27\n",
      "hv :  [[3.2532278e+13]\n",
      " [6.5490806e+13]\n",
      " [5.1519257e+13]\n",
      " [3.6114723e+13]\n",
      " [4.2563134e+13]\n",
      " [4.2921378e+13]\n",
      " [3.9338931e+13]\n",
      " [5.0086277e+13]]\n",
      "3\n",
      "cv :  inf\n",
      "hv :  [[-1.0783263e+21]\n",
      " [-2.1707815e+21]\n",
      " [-1.7076755e+21]\n",
      " [-1.1970714e+21]\n",
      " [-1.4108127e+21]\n",
      " [-1.4226871e+21]\n",
      " [-1.3039420e+21]\n",
      " [-1.6601774e+21]]\n",
      "4\n",
      "cv :  inf\n",
      "hv :  [[3.5742584e+28]\n",
      " [7.1953489e+28]\n",
      " [5.6603215e+28]\n",
      " [3.9678551e+28]\n",
      " [4.6763295e+28]\n",
      " [4.7156891e+28]\n",
      " [4.3220916e+28]\n",
      " [5.5028820e+28]]\n",
      "5\n",
      "cv :  inf\n",
      "hv :  [[-1.1847360e+36]\n",
      " [-2.3849951e+36]\n",
      " [-1.8761896e+36]\n",
      " [-1.3151990e+36]\n",
      " [-1.5500323e+36]\n",
      " [-1.5630785e+36]\n",
      " [-1.4326155e+36]\n",
      " [-1.8240044e+36]]\n",
      "6\n",
      "cv :  inf\n",
      "hv :  [[inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "7\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "8\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "9\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "10\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "11\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "12\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "13\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "14\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "15\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "16\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "17\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "18\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "19\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "20\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "21\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "22\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "23\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "24\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "25\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "26\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "27\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "28\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "29\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "30\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "31\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "32\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "33\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "34\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "35\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "36\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "37\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "38\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "39\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "40\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "41\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "42\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "43\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "44\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "45\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "46\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "47\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "48\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "49\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "50\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "51\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "52\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "53\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "54\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "55\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "56\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "57\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "58\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "59\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "60\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "61\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "62\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "63\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "64\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "65\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "66\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "67\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "68\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "69\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "70\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "71\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "72\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "73\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "74\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "75\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "76\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "77\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "78\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "79\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "80\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "81\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "82\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "83\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "84\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "85\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "86\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "87\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "88\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "89\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "90\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "91\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "92\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "93\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "94\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "95\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "96\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "97\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "98\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "99\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "100\n",
      "cv :  nan\n",
      "hv :  [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1,101):\n",
    "        _,cv,hv =  sess.run([train, cost, hf], feed_dict={x:xdata, y:ydata})\n",
    "        print(step)\n",
    "        print('cv : ',cv)\n",
    "        print('hv : ',hv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nan나오는 건 data가 scale이 되어있지 않아서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMinMax(data):\n",
    "#     print(np.min(data)) # 전체에서 최소값\n",
    "#     print(np.min(data, axis=1)) # 행 단위 최소값\n",
    "#     print(np.min(data, axis=0)) # 열 단위 최소값\n",
    "    bm = np.max(data,axis=0) - np.min(data, axis=0)\n",
    "    bj = data - np.min(data, axis=0)\n",
    "    return bj/bm\n",
    "#     return data\n",
    "\n",
    "\n",
    "xy = myMinMax(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = xy[:,:-1]\n",
    "ydata = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "cv :  6.5742273\n",
      "hv :  [[3.4595268]\n",
      " [4.855599 ]\n",
      " [3.621671 ]\n",
      " [2.2294385]\n",
      " [2.9622133]\n",
      " [2.770822 ]\n",
      " [1.7863977]\n",
      " [2.0593371]]\n",
      "2\n",
      "cv :  6.573741\n",
      "hv :  [[3.459401 ]\n",
      " [4.8554735]\n",
      " [3.6215665]\n",
      " [2.2293582]\n",
      " [2.9621181]\n",
      " [2.77073  ]\n",
      " [1.786335 ]\n",
      " [2.0592742]]\n",
      "3\n",
      "cv :  6.5732546\n",
      "hv :  [[3.4592755]\n",
      " [4.8553476]\n",
      " [3.6214623]\n",
      " [2.229278 ]\n",
      " [2.9620233]\n",
      " [2.770638 ]\n",
      " [1.7862723]\n",
      " [2.0592115]]\n",
      "4\n",
      "cv :  6.5727677\n",
      "hv :  [[3.4591496]\n",
      " [4.855222 ]\n",
      " [3.6213582]\n",
      " [2.2291977]\n",
      " [2.9619277]\n",
      " [2.770546 ]\n",
      " [1.7862096]\n",
      " [2.0591486]]\n",
      "5\n",
      "cv :  6.572281\n",
      "hv :  [[3.4590242]\n",
      " [4.8550963]\n",
      " [3.6212537]\n",
      " [2.2291176]\n",
      " [2.9618328]\n",
      " [2.770454 ]\n",
      " [1.7861469]\n",
      " [2.0590856]]\n",
      "6\n",
      "cv :  6.5717945\n",
      "hv :  [[3.4588985]\n",
      " [4.854971 ]\n",
      " [3.6211495]\n",
      " [2.2290373]\n",
      " [2.9617376]\n",
      " [2.770362 ]\n",
      " [1.7860842]\n",
      " [2.0590227]]\n",
      "7\n",
      "cv :  6.571308\n",
      "hv :  [[3.4587731]\n",
      " [4.8548455]\n",
      " [3.6210454]\n",
      " [2.2289572]\n",
      " [2.9616427]\n",
      " [2.7702699]\n",
      " [1.7860215]\n",
      " [2.05896  ]]\n",
      "8\n",
      "cv :  6.5708213\n",
      "hv :  [[3.4586473]\n",
      " [4.8547196]\n",
      " [3.620941 ]\n",
      " [2.228877 ]\n",
      " [2.9615476]\n",
      " [2.7701778]\n",
      " [1.7859588]\n",
      " [2.058897 ]]\n",
      "9\n",
      "cv :  6.5703344\n",
      "hv :  [[3.4585218]\n",
      " [4.8545938]\n",
      " [3.620837 ]\n",
      " [2.2287967]\n",
      " [2.9614527]\n",
      " [2.770086 ]\n",
      " [1.7858961]\n",
      " [2.058834 ]]\n",
      "10\n",
      "cv :  6.569848\n",
      "hv :  [[3.4583962]\n",
      " [4.8544683]\n",
      " [3.6207325]\n",
      " [2.2287164]\n",
      " [2.9613576]\n",
      " [2.769994 ]\n",
      " [1.7858334]\n",
      " [2.0587711]]\n",
      "11\n",
      "cv :  6.5693626\n",
      "hv :  [[3.4582705]\n",
      " [4.854343 ]\n",
      " [3.6206284]\n",
      " [2.2286365]\n",
      " [2.9612625]\n",
      " [2.769902 ]\n",
      " [1.7857707]\n",
      " [2.0587082]]\n",
      "12\n",
      "cv :  6.568876\n",
      "hv :  [[3.458145 ]\n",
      " [4.8542175]\n",
      " [3.620524 ]\n",
      " [2.2285562]\n",
      " [2.9611673]\n",
      " [2.76981  ]\n",
      " [1.785708 ]\n",
      " [2.0586452]]\n",
      "13\n",
      "cv :  6.5683885\n",
      "hv :  [[3.4580195]\n",
      " [4.854091 ]\n",
      " [3.6204197]\n",
      " [2.2284758]\n",
      " [2.9610724]\n",
      " [2.769718 ]\n",
      " [1.7856454]\n",
      " [2.0585825]]\n",
      "14\n",
      "cv :  6.5679026\n",
      "hv :  [[3.4578938]\n",
      " [4.8539658]\n",
      " [3.6203156]\n",
      " [2.2283957]\n",
      " [2.960977 ]\n",
      " [2.769626 ]\n",
      " [1.7855828]\n",
      " [2.0585196]]\n",
      "15\n",
      "cv :  6.5674167\n",
      "hv :  [[3.4577682]\n",
      " [4.8538404]\n",
      " [3.6202114]\n",
      " [2.2283156]\n",
      " [2.9608822]\n",
      " [2.7695339]\n",
      " [1.78552  ]\n",
      " [2.0584567]]\n",
      "16\n",
      "cv :  6.56693\n",
      "hv :  [[3.4576426]\n",
      " [4.853715 ]\n",
      " [3.620107 ]\n",
      " [2.2282352]\n",
      " [2.960787 ]\n",
      " [2.7694418]\n",
      " [1.7854574]\n",
      " [2.0583937]]\n",
      "17\n",
      "cv :  6.566444\n",
      "hv :  [[3.4575171]\n",
      " [4.853589 ]\n",
      " [3.6200027]\n",
      " [2.2281551]\n",
      " [2.9606922]\n",
      " [2.7693498]\n",
      " [1.7853947]\n",
      " [2.058331 ]]\n",
      "18\n",
      "cv :  6.565957\n",
      "hv :  [[3.4573913]\n",
      " [4.8534636]\n",
      " [3.6198983]\n",
      " [2.2280748]\n",
      " [2.960597 ]\n",
      " [2.7692578]\n",
      " [1.785332 ]\n",
      " [2.058268 ]]\n",
      "19\n",
      "cv :  6.5654707\n",
      "hv :  [[3.4572659]\n",
      " [4.853338 ]\n",
      " [3.6197944]\n",
      " [2.2279947]\n",
      " [2.960502 ]\n",
      " [2.7691658]\n",
      " [1.7852693]\n",
      " [2.0582051]]\n",
      "20\n",
      "cv :  6.5649843\n",
      "hv :  [[3.4571402]\n",
      " [4.8532124]\n",
      " [3.6196897]\n",
      " [2.2279143]\n",
      " [2.9604068]\n",
      " [2.7690737]\n",
      " [1.7852066]\n",
      " [2.0581422]]\n",
      "21\n",
      "cv :  6.564498\n",
      "hv :  [[3.4570148]\n",
      " [4.8530865]\n",
      " [3.6195858]\n",
      " [2.2278342]\n",
      " [2.960312 ]\n",
      " [2.768982 ]\n",
      " [1.7851439]\n",
      " [2.0580795]]\n",
      "22\n",
      "cv :  6.564012\n",
      "hv :  [[3.4568892]\n",
      " [4.852961 ]\n",
      " [3.6194816]\n",
      " [2.227754 ]\n",
      " [2.9602165]\n",
      " [2.7688897]\n",
      " [1.7850811]\n",
      " [2.0580165]]\n",
      "23\n",
      "cv :  6.563525\n",
      "hv :  [[3.4567637]\n",
      " [4.852835 ]\n",
      " [3.6193771]\n",
      " [2.2276738]\n",
      " [2.9601216]\n",
      " [2.7687979]\n",
      " [1.7850184]\n",
      " [2.0579536]]\n",
      "24\n",
      "cv :  6.56304\n",
      "hv :  [[3.4566379]\n",
      " [4.8527102]\n",
      " [3.6192727]\n",
      " [2.2275937]\n",
      " [2.9600265]\n",
      " [2.7687058]\n",
      " [1.7849557]\n",
      " [2.0578907]]\n",
      "25\n",
      "cv :  6.562554\n",
      "hv :  [[3.4565125]\n",
      " [4.8525844]\n",
      " [3.6191688]\n",
      " [2.2275136]\n",
      " [2.9599316]\n",
      " [2.7686138]\n",
      " [1.784893 ]\n",
      " [2.0578277]]\n",
      "26\n",
      "cv :  6.562067\n",
      "hv :  [[3.4563868]\n",
      " [4.8524585]\n",
      " [3.6190643]\n",
      " [2.2274332]\n",
      " [2.9598365]\n",
      " [2.7685218]\n",
      " [1.7848303]\n",
      " [2.0577648]]\n",
      "27\n",
      "cv :  6.5615816\n",
      "hv :  [[3.4562614]\n",
      " [4.852333 ]\n",
      " [3.6189601]\n",
      " [2.227353 ]\n",
      " [2.9597416]\n",
      " [2.7684298]\n",
      " [1.7847676]\n",
      " [2.057702 ]]\n",
      "28\n",
      "cv :  6.5610957\n",
      "hv :  [[3.4561357]\n",
      " [4.8522077]\n",
      " [3.6188557]\n",
      " [2.227273 ]\n",
      " [2.9596465]\n",
      " [2.7683377]\n",
      " [1.7847049]\n",
      " [2.0576391]]\n",
      "29\n",
      "cv :  6.5606093\n",
      "hv :  [[3.4560103]\n",
      " [4.852082 ]\n",
      " [3.6187518]\n",
      " [2.2271926]\n",
      " [2.9595513]\n",
      " [2.768246 ]\n",
      " [1.7846423]\n",
      " [2.0575762]]\n",
      "30\n",
      "cv :  6.5601234\n",
      "hv :  [[3.4558847]\n",
      " [4.8519564]\n",
      " [3.6186476]\n",
      " [2.2271125]\n",
      " [2.9594562]\n",
      " [2.7681537]\n",
      " [1.7845798]\n",
      " [2.0575132]]\n",
      "31\n",
      "cv :  6.559638\n",
      "hv :  [[3.4557593]\n",
      " [4.851831 ]\n",
      " [3.6185431]\n",
      " [2.2270322]\n",
      " [2.9593613]\n",
      " [2.7680619]\n",
      " [1.784517 ]\n",
      " [2.0574505]]\n",
      "32\n",
      "cv :  6.559152\n",
      "hv :  [[3.4556336]\n",
      " [4.8517056]\n",
      " [3.6184392]\n",
      " [2.226952 ]\n",
      " [2.9592662]\n",
      " [2.76797  ]\n",
      " [1.7844543]\n",
      " [2.0573876]]\n",
      "33\n",
      "cv :  6.558666\n",
      "hv :  [[3.455508 ]\n",
      " [4.8515797]\n",
      " [3.6183348]\n",
      " [2.226872 ]\n",
      " [2.9591713]\n",
      " [2.767878 ]\n",
      " [1.7843916]\n",
      " [2.057325 ]]\n",
      "34\n",
      "cv :  6.55818\n",
      "hv :  [[3.4553826]\n",
      " [4.8514543]\n",
      " [3.6182306]\n",
      " [2.2267919]\n",
      " [2.9590762]\n",
      " [2.767786 ]\n",
      " [1.784329 ]\n",
      " [2.057262 ]]\n",
      "35\n",
      "cv :  6.557695\n",
      "hv :  [[3.4552572]\n",
      " [4.851329 ]\n",
      " [3.6181266]\n",
      " [2.2267118]\n",
      " [2.9589813]\n",
      " [2.7676942]\n",
      " [1.7842665]\n",
      " [2.0571992]]\n",
      "36\n",
      "cv :  6.5572095\n",
      "hv :  [[3.4551315]\n",
      " [4.8512034]\n",
      " [3.6180224]\n",
      " [2.2266316]\n",
      " [2.9588861]\n",
      " [2.7676022]\n",
      " [1.7842038]\n",
      " [2.0571363]]\n",
      "37\n",
      "cv :  6.5567236\n",
      "hv :  [[3.4550061]\n",
      " [4.8510776]\n",
      " [3.617918 ]\n",
      " [2.2265515]\n",
      " [2.9587913]\n",
      " [2.7675102]\n",
      " [1.7841413]\n",
      " [2.0570736]]\n",
      "38\n",
      "cv :  6.556238\n",
      "hv :  [[3.4548807]\n",
      " [4.850952 ]\n",
      " [3.6178138]\n",
      " [2.2264714]\n",
      " [2.9586964]\n",
      " [2.7674184]\n",
      " [1.7840786]\n",
      " [2.0570107]]\n",
      "39\n",
      "cv :  6.5557528\n",
      "hv :  [[3.4547553]\n",
      " [4.8508267]\n",
      " [3.6177099]\n",
      " [2.2263913]\n",
      " [2.9586015]\n",
      " [2.7673264]\n",
      " [1.7840159]\n",
      " [2.056948 ]]\n",
      "40\n",
      "cv :  6.555267\n",
      "hv :  [[3.45463  ]\n",
      " [4.850701 ]\n",
      " [3.6176057]\n",
      " [2.2263112]\n",
      " [2.9585066]\n",
      " [2.7672343]\n",
      " [1.7839534]\n",
      " [2.0568848]]\n",
      "41\n",
      "cv :  6.5547814\n",
      "hv :  [[3.4545043]\n",
      " [4.8505754]\n",
      " [3.6175015]\n",
      " [2.2262309]\n",
      " [2.9584115]\n",
      " [2.7671425]\n",
      " [1.7838907]\n",
      " [2.056822 ]]\n",
      "42\n",
      "cv :  6.5542965\n",
      "hv :  [[3.4543788]\n",
      " [4.85045  ]\n",
      " [3.6173973]\n",
      " [2.226151 ]\n",
      " [2.9583166]\n",
      " [2.7670507]\n",
      " [1.783828 ]\n",
      " [2.0567594]]\n",
      "43\n",
      "cv :  6.553811\n",
      "hv :  [[3.4542534]\n",
      " [4.8503246]\n",
      " [3.6172931]\n",
      " [2.2260706]\n",
      " [2.9582217]\n",
      " [2.7669587]\n",
      " [1.7837656]\n",
      " [2.0566964]]\n",
      "44\n",
      "cv :  6.5533257\n",
      "hv :  [[3.4541278]\n",
      " [4.850199 ]\n",
      " [3.617189 ]\n",
      " [2.2259905]\n",
      " [2.9581265]\n",
      " [2.7668667]\n",
      " [1.7837029]\n",
      " [2.0566335]]\n",
      "45\n",
      "cv :  6.5528393\n",
      "hv :  [[3.4540024]\n",
      " [4.8500733]\n",
      " [3.6170845]\n",
      " [2.2259104]\n",
      " [2.9580314]\n",
      " [2.766775 ]\n",
      " [1.7836401]\n",
      " [2.0565708]]\n",
      "46\n",
      "cv :  6.5523543\n",
      "hv :  [[3.453877 ]\n",
      " [4.849948 ]\n",
      " [3.6169806]\n",
      " [2.2258303]\n",
      " [2.9579365]\n",
      " [2.7666829]\n",
      " [1.7835776]\n",
      " [2.056508 ]]\n",
      "47\n",
      "cv :  6.5518694\n",
      "hv :  [[3.4537516]\n",
      " [4.8498225]\n",
      " [3.6168766]\n",
      " [2.2257502]\n",
      " [2.9578416]\n",
      " [2.766591 ]\n",
      " [1.783515 ]\n",
      " [2.0564451]]\n",
      "48\n",
      "cv :  6.5513835\n",
      "hv :  [[3.4536262]\n",
      " [4.849697 ]\n",
      " [3.6167722]\n",
      " [2.2256699]\n",
      " [2.9577465]\n",
      " [2.766499 ]\n",
      " [1.7834523]\n",
      " [2.0563822]]\n",
      "49\n",
      "cv :  6.5508986\n",
      "hv :  [[3.4535005]\n",
      " [4.8495717]\n",
      " [3.616668 ]\n",
      " [2.22559  ]\n",
      " [2.9576516]\n",
      " [2.7664073]\n",
      " [1.7833898]\n",
      " [2.0563195]]\n",
      "50\n",
      "cv :  6.550414\n",
      "hv :  [[3.453375 ]\n",
      " [4.8494463]\n",
      " [3.616564 ]\n",
      " [2.22551  ]\n",
      " [2.9575567]\n",
      " [2.7663155]\n",
      " [1.7833271]\n",
      " [2.0562568]]\n",
      "51\n",
      "cv :  6.5499296\n",
      "hv :  [[3.4532497]\n",
      " [4.849321 ]\n",
      " [3.61646  ]\n",
      " [2.2254298]\n",
      " [2.957462 ]\n",
      " [2.7662234]\n",
      " [1.7832646]\n",
      " [2.056194 ]]\n",
      "52\n",
      "cv :  6.5494447\n",
      "hv :  [[3.453124 ]\n",
      " [4.849196 ]\n",
      " [3.616356 ]\n",
      " [2.2253494]\n",
      " [2.957367 ]\n",
      " [2.7661319]\n",
      " [1.7832019]\n",
      " [2.0561314]]\n",
      "53\n",
      "cv :  6.5489597\n",
      "hv :  [[3.4529986]\n",
      " [4.8490705]\n",
      " [3.616252 ]\n",
      " [2.2252696]\n",
      " [2.957272 ]\n",
      " [2.7660398]\n",
      " [1.7831395]\n",
      " [2.0560687]]\n",
      "54\n",
      "cv :  6.5484753\n",
      "hv :  [[3.4528732]\n",
      " [4.848945 ]\n",
      " [3.616148 ]\n",
      " [2.2251894]\n",
      " [2.9571772]\n",
      " [2.765948 ]\n",
      " [1.7830769]\n",
      " [2.056006 ]]\n",
      "55\n",
      "cv :  6.5479903\n",
      "hv :  [[3.4527478]\n",
      " [4.8488197]\n",
      " [3.616044 ]\n",
      " [2.2251093]\n",
      " [2.9570823]\n",
      " [2.7658563]\n",
      " [1.7830143]\n",
      " [2.0559433]]\n",
      "56\n",
      "cv :  6.5475063\n",
      "hv :  [[3.4526224]\n",
      " [4.848695 ]\n",
      " [3.61594  ]\n",
      " [2.2250295]\n",
      " [2.9569874]\n",
      " [2.7657642]\n",
      " [1.7829517]\n",
      " [2.0558805]]\n",
      "57\n",
      "cv :  6.547021\n",
      "hv :  [[3.4524968]\n",
      " [4.8485694]\n",
      " [3.615836 ]\n",
      " [2.2249491]\n",
      " [2.9568923]\n",
      " [2.7656724]\n",
      " [1.7828891]\n",
      " [2.0558178]]\n",
      "58\n",
      "cv :  6.5465364\n",
      "hv :  [[3.4523714]\n",
      " [4.848444 ]\n",
      " [3.615732 ]\n",
      " [2.224869 ]\n",
      " [2.9567976]\n",
      " [2.7655807]\n",
      " [1.7828265]\n",
      " [2.0557551]]\n",
      "59\n",
      "cv :  6.546053\n",
      "hv :  [[3.4522462]\n",
      " [4.848319 ]\n",
      " [3.615628 ]\n",
      " [2.2247891]\n",
      " [2.956703 ]\n",
      " [2.7654889]\n",
      " [1.782764 ]\n",
      " [2.0556924]]\n",
      "60\n",
      "cv :  6.5455675\n",
      "hv :  [[3.4521208]\n",
      " [4.8481936]\n",
      " [3.6155238]\n",
      " [2.224709 ]\n",
      " [2.9566078]\n",
      " [2.765397 ]\n",
      " [1.7827014]\n",
      " [2.0556297]]\n",
      "61\n",
      "cv :  6.545084\n",
      "hv :  [[3.4519951]\n",
      " [4.8480687]\n",
      " [3.6154199]\n",
      " [2.2246287]\n",
      " [2.956513 ]\n",
      " [2.7653053]\n",
      " [1.7826388]\n",
      " [2.055567 ]]\n",
      "62\n",
      "cv :  6.5445995\n",
      "hv :  [[3.4518697]\n",
      " [4.8479433]\n",
      " [3.615316 ]\n",
      " [2.2245488]\n",
      " [2.956418 ]\n",
      " [2.7652135]\n",
      " [1.7825762]\n",
      " [2.0555043]]\n",
      "63\n",
      "cv :  6.544115\n",
      "hv :  [[3.4517446]\n",
      " [4.847818 ]\n",
      " [3.615212 ]\n",
      " [2.2244687]\n",
      " [2.9563231]\n",
      " [2.7651217]\n",
      " [1.7825136]\n",
      " [2.0554416]]\n",
      "64\n",
      "cv :  6.5436306\n",
      "hv :  [[3.4516191]\n",
      " [4.847693 ]\n",
      " [3.615108 ]\n",
      " [2.2243886]\n",
      " [2.9562285]\n",
      " [2.76503  ]\n",
      " [1.7824512]\n",
      " [2.0553792]]\n",
      "65\n",
      "cv :  6.5431466\n",
      "hv :  [[3.4514937]\n",
      " [4.8475676]\n",
      " [3.615004 ]\n",
      " [2.2243085]\n",
      " [2.9561336]\n",
      " [2.764938 ]\n",
      " [1.7823887]\n",
      " [2.0553164]]\n",
      "66\n",
      "cv :  6.5426626\n",
      "hv :  [[3.4513683]\n",
      " [4.8474426]\n",
      " [3.6149   ]\n",
      " [2.2242286]\n",
      " [2.956039 ]\n",
      " [2.7648463]\n",
      " [1.7823262]\n",
      " [2.0552537]]\n",
      "67\n",
      "cv :  6.542178\n",
      "hv :  [[3.451243 ]\n",
      " [4.847317 ]\n",
      " [3.6147962]\n",
      " [2.2241485]\n",
      " [2.955944 ]\n",
      " [2.7647545]\n",
      " [1.7822635]\n",
      " [2.055191 ]]\n",
      "68\n",
      "cv :  6.5416946\n",
      "hv :  [[3.4511175]\n",
      " [4.8471923]\n",
      " [3.6146922]\n",
      " [2.2240684]\n",
      " [2.9558492]\n",
      " [2.7646627]\n",
      " [1.782201 ]\n",
      " [2.0551286]]\n",
      "69\n",
      "cv :  6.54121\n",
      "hv :  [[3.450992 ]\n",
      " [4.847067 ]\n",
      " [3.6145883]\n",
      " [2.2239885]\n",
      " [2.9557543]\n",
      " [2.764571 ]\n",
      " [1.7821386]\n",
      " [2.0550659]]\n",
      "70\n",
      "cv :  6.5407267\n",
      "hv :  [[3.450867 ]\n",
      " [4.846942 ]\n",
      " [3.6144843]\n",
      " [2.2239084]\n",
      " [2.9556594]\n",
      " [2.7644792]\n",
      " [1.7820761]\n",
      " [2.0550032]]\n",
      "71\n",
      "cv :  6.540242\n",
      "hv :  [[3.4507415]\n",
      " [4.8468165]\n",
      " [3.6143804]\n",
      " [2.2238286]\n",
      " [2.9555647]\n",
      " [2.7643874]\n",
      " [1.7820137]\n",
      " [2.0549405]]\n",
      "72\n",
      "cv :  6.5397587\n",
      "hv :  [[3.4506161]\n",
      " [4.8466916]\n",
      " [3.6142764]\n",
      " [2.2237484]\n",
      " [2.9554698]\n",
      " [2.7642956]\n",
      " [1.781951 ]\n",
      " [2.054878 ]]\n",
      "73\n",
      "cv :  6.539275\n",
      "hv :  [[3.450491 ]\n",
      " [4.846566 ]\n",
      " [3.6141725]\n",
      " [2.2236683]\n",
      " [2.955375 ]\n",
      " [2.764204 ]\n",
      " [1.7818885]\n",
      " [2.0548153]]\n",
      "74\n",
      "cv :  6.53879\n",
      "hv :  [[3.4503655]\n",
      " [4.846441 ]\n",
      " [3.6140685]\n",
      " [2.2235885]\n",
      " [2.9552803]\n",
      " [2.764112 ]\n",
      " [1.781826 ]\n",
      " [2.0547526]]\n",
      "75\n",
      "cv :  6.538307\n",
      "hv :  [[3.4502401]\n",
      " [4.846316 ]\n",
      " [3.6139646]\n",
      " [2.2235084]\n",
      " [2.9551854]\n",
      " [2.7640204]\n",
      " [1.7817636]\n",
      " [2.05469  ]]\n",
      "76\n",
      "cv :  6.5378227\n",
      "hv :  [[3.4501147]\n",
      " [4.8461905]\n",
      " [3.6138606]\n",
      " [2.2234282]\n",
      " [2.9550905]\n",
      " [2.7639287]\n",
      " [1.781701 ]\n",
      " [2.0546274]]\n",
      "77\n",
      "cv :  6.537339\n",
      "hv :  [[3.4499893]\n",
      " [4.8460655]\n",
      " [3.6137567]\n",
      " [2.2233484]\n",
      " [2.9549959]\n",
      " [2.7638369]\n",
      " [1.7816384]\n",
      " [2.0545647]]\n",
      "78\n",
      "cv :  6.5368547\n",
      "hv :  [[3.449864 ]\n",
      " [4.84594  ]\n",
      " [3.6136527]\n",
      " [2.2232683]\n",
      " [2.954901 ]\n",
      " [2.763745 ]\n",
      " [1.7815759]\n",
      " [2.054502 ]]\n",
      "79\n",
      "cv :  6.536371\n",
      "hv :  [[3.4497387]\n",
      " [4.845815 ]\n",
      " [3.6135488]\n",
      " [2.2231882]\n",
      " [2.954806 ]\n",
      " [2.7636533]\n",
      " [1.7815135]\n",
      " [2.0544393]]\n",
      "80\n",
      "cv :  6.535888\n",
      "hv :  [[3.4496133]\n",
      " [4.8456903]\n",
      " [3.6134448]\n",
      " [2.2231083]\n",
      " [2.9547112]\n",
      " [2.7635615]\n",
      " [1.781451 ]\n",
      " [2.0543768]]\n",
      "81\n",
      "cv :  6.535404\n",
      "hv :  [[3.449488 ]\n",
      " [4.845565 ]\n",
      " [3.6133409]\n",
      " [2.2230282]\n",
      " [2.9546165]\n",
      " [2.7634697]\n",
      " [1.7813884]\n",
      " [2.0543141]]\n",
      "82\n",
      "cv :  6.53492\n",
      "hv :  [[3.4493628]\n",
      " [4.84544  ]\n",
      " [3.613237 ]\n",
      " [2.222948 ]\n",
      " [2.9545217]\n",
      " [2.763378 ]\n",
      " [1.7813258]\n",
      " [2.0542514]]\n",
      "83\n",
      "cv :  6.534436\n",
      "hv :  [[3.4492373]\n",
      " [4.8453145]\n",
      " [3.613133 ]\n",
      " [2.2228682]\n",
      " [2.9544268]\n",
      " [2.7632864]\n",
      " [1.7812634]\n",
      " [2.0541887]]\n",
      "84\n",
      "cv :  6.5339537\n",
      "hv :  [[3.449112 ]\n",
      " [4.8451896]\n",
      " [3.613029 ]\n",
      " [2.222788 ]\n",
      " [2.954332 ]\n",
      " [2.7631946]\n",
      " [1.7812009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [2.0541263]]\n",
      "85\n",
      "cv :  6.533469\n",
      "hv :  [[3.4489865]\n",
      " [4.845064 ]\n",
      " [3.612925 ]\n",
      " [2.2227082]\n",
      " [2.9542375]\n",
      " [2.7631028]\n",
      " [1.7811384]\n",
      " [2.0540636]]\n",
      "86\n",
      "cv :  6.5329857\n",
      "hv :  [[3.4488614]\n",
      " [4.844939 ]\n",
      " [3.612821 ]\n",
      " [2.222628 ]\n",
      " [2.9541426]\n",
      " [2.763011 ]\n",
      " [1.781076 ]\n",
      " [2.0540009]]\n",
      "87\n",
      "cv :  6.532502\n",
      "hv :  [[3.448736 ]\n",
      " [4.844814 ]\n",
      " [3.6127172]\n",
      " [2.222548 ]\n",
      " [2.9540477]\n",
      " [2.7629194]\n",
      " [1.7810133]\n",
      " [2.0539384]]\n",
      "88\n",
      "cv :  6.5320187\n",
      "hv :  [[3.4486108]\n",
      " [4.844689 ]\n",
      " [3.6126134]\n",
      " [2.2224681]\n",
      " [2.9539528]\n",
      " [2.7628276]\n",
      " [1.7809508]\n",
      " [2.0538757]]\n",
      "89\n",
      "cv :  6.531535\n",
      "hv :  [[3.4484854]\n",
      " [4.8445635]\n",
      " [3.6125095]\n",
      " [2.222388 ]\n",
      " [2.9538581]\n",
      " [2.7627358]\n",
      " [1.7808883]\n",
      " [2.053813 ]]\n",
      "90\n",
      "cv :  6.5310516\n",
      "hv :  [[3.44836  ]\n",
      " [4.8444386]\n",
      " [3.6124055]\n",
      " [2.2223082]\n",
      " [2.9537632]\n",
      " [2.762644 ]\n",
      " [1.7808259]\n",
      " [2.0537503]]\n",
      "91\n",
      "cv :  6.5305686\n",
      "hv :  [[3.4482348]\n",
      " [4.8443136]\n",
      " [3.6123016]\n",
      " [2.222228 ]\n",
      " [2.9536686]\n",
      " [2.7625523]\n",
      " [1.7807634]\n",
      " [2.0536878]]\n",
      "92\n",
      "cv :  6.5300846\n",
      "hv :  [[3.4481094]\n",
      " [4.844188 ]\n",
      " [3.6121979]\n",
      " [2.222148 ]\n",
      " [2.9535737]\n",
      " [2.7624607]\n",
      " [1.7807008]\n",
      " [2.053625 ]]\n",
      "93\n",
      "cv :  6.5296016\n",
      "hv :  [[3.4479842]\n",
      " [4.8440633]\n",
      " [3.612094 ]\n",
      " [2.222068 ]\n",
      " [2.9534788]\n",
      " [2.762369 ]\n",
      " [1.7806382]\n",
      " [2.0535624]]\n",
      "94\n",
      "cv :  6.5291176\n",
      "hv :  [[3.4478588]\n",
      " [4.843938 ]\n",
      " [3.61199  ]\n",
      " [2.221988 ]\n",
      " [2.953384 ]\n",
      " [2.7622771]\n",
      " [1.7805758]\n",
      " [2.0534997]]\n",
      "95\n",
      "cv :  6.5286345\n",
      "hv :  [[3.4477334]\n",
      " [4.843813 ]\n",
      " [3.611886 ]\n",
      " [2.221908 ]\n",
      " [2.9532893]\n",
      " [2.7621853]\n",
      " [1.7805133]\n",
      " [2.0534372]]\n",
      "96\n",
      "cv :  6.5281515\n",
      "hv :  [[3.4476082]\n",
      " [4.843688 ]\n",
      " [3.611782 ]\n",
      " [2.221828 ]\n",
      " [2.9531946]\n",
      " [2.7620935]\n",
      " [1.7804508]\n",
      " [2.0533748]]\n",
      "97\n",
      "cv :  6.5276685\n",
      "hv :  [[3.447483 ]\n",
      " [4.8435626]\n",
      " [3.6116781]\n",
      " [2.221748 ]\n",
      " [2.9530997]\n",
      " [2.762002 ]\n",
      " [1.7803884]\n",
      " [2.053312 ]]\n",
      "98\n",
      "cv :  6.5271845\n",
      "hv :  [[3.4473577]\n",
      " [4.8434377]\n",
      " [3.6115742]\n",
      " [2.2216682]\n",
      " [2.9530048]\n",
      " [2.7619104]\n",
      " [1.7803259]\n",
      " [2.0532494]]\n",
      "99\n",
      "cv :  6.526702\n",
      "hv :  [[3.4472325]\n",
      " [4.8433123]\n",
      " [3.6114705]\n",
      " [2.2215881]\n",
      " [2.9529102]\n",
      " [2.7618186]\n",
      " [1.7802634]\n",
      " [2.053187 ]]\n",
      "100\n",
      "cv :  6.5262194\n",
      "hv :  [[3.4471073]\n",
      " [4.8431873]\n",
      " [3.6113665]\n",
      " [2.2215083]\n",
      " [2.9528155]\n",
      " [2.7617269]\n",
      " [1.780201 ]\n",
      " [2.0531244]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,4])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([4,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hf = tf.matmul(x,w) +b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hf-y)) # regression\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(1e-5).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1,101):\n",
    "        _,cv,hv, bv, wv =  sess.run([train, cost, hf, b, w], feed_dict={x:xdata, y:ydata})\n",
    "        print(step)\n",
    "        print('cv : ',cv)\n",
    "        print('hv : ',hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5619142],\n",
       "       [3.9579942],\n",
       "       [2.7261734],\n",
       "       [1.3363152],\n",
       "       [2.0676224],\n",
       "       [1.8765337],\n",
       "       [0.8950078],\n",
       "       [1.1679313]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 역정규화\n",
    "(hv - bv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02701651],\n",
       "       [0.47512954],\n",
       "       [2.1236224 ],\n",
       "       [2.0596428 ]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor문제를 tensorflow로 구현\n",
    "# 단일 퍼셉트론\n",
    "# 멀티 페셉트론\n",
    "# 으로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.array([[0,0,],[0,1],[1,0],[1,1]])\n",
    "ydata = np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata.shape, ydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,2])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([2,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hf = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "\n",
    "cost = tf.reduce_mean(-y*tf.log(hf)-(1-y)*tf.log(1-hf))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.695536 [[ 0.16460477]\n",
      " [-0.21645173]]\n",
      "200 0.6938134 [[ 0.08995546]\n",
      " [-0.11383293]]\n",
      "300 0.69333905 [[ 0.04648753]\n",
      " [-0.0624128 ]]\n",
      "400 0.6932027 [[ 0.02371754]\n",
      " [-0.03446359]]\n",
      "500 0.6931633 [[ 0.01191433]\n",
      " [-0.01916755]]\n",
      "600 0.69315195 [[ 0.00585439]\n",
      " [-0.01075006]]\n",
      "700 0.6931486 [[ 0.00278296]\n",
      " [-0.00608736]]\n",
      "800 0.69314766 [[ 0.00125414]\n",
      " [-0.00348449]]\n",
      "900 0.69314736 [[ 0.000513  ]\n",
      " [-0.00201844]]\n",
      "1000 0.6931472 [[ 0.00016811]\n",
      " [-0.00118422]]\n",
      "1100 0.6931472 [[ 1.8328481e-05]\n",
      " [-7.0408976e-04]]\n",
      "1200 0.6931472 [[-3.8504553e-05]\n",
      " [-4.2441898e-04]]\n",
      "1300 0.6931471 [[-5.3155363e-05]\n",
      " [-2.5931268e-04]]\n",
      "1400 0.6931472 [[-5.0385250e-05]\n",
      " [-1.6051054e-04]]\n",
      "1500 0.6931472 [[-4.1757485e-05]\n",
      " [-1.0057804e-04]]\n",
      "1600 0.6931472 [[-3.2323613e-05]\n",
      " [-6.3733409e-05]]\n",
      "1700 0.6931472 [[-2.4029634e-05]\n",
      " [-4.0796032e-05]]\n",
      "1800 0.6931472 [[-1.7401597e-05]\n",
      " [-2.6344893e-05]]\n",
      "1900 0.6931472 [[-1.2373948e-05]\n",
      " [-1.7149388e-05]]\n",
      "2000 0.6931472 [[-8.6859109e-06]\n",
      " [-1.1230645e-05]]\n",
      "2100 0.6931472 [[-6.0335014e-06]\n",
      " [-7.3906122e-06]]\n",
      "2200 0.6931472 [[-4.181286e-06]\n",
      " [-4.869338e-06]]\n",
      "2300 0.6931472 [[-2.8640241e-06]\n",
      " [-3.2570294e-06]]\n",
      "2400 0.6931472 [[-1.9535603e-06]\n",
      " [-2.1409335e-06]]\n",
      "2500 0.6931472 [[-1.3396306e-06]\n",
      " [-1.4301470e-06]]\n",
      "2600 0.6931472 [[-8.9259197e-07]\n",
      " [-9.8310761e-07]]\n",
      "2700 0.69314724 [[-6.422526e-07]\n",
      " [-6.508113e-07]]\n",
      "2800 0.6931471 [[-4.1277454e-07]\n",
      " [-4.1239232e-07]]\n",
      "2900 0.6931472 [[-2.6078212e-07]\n",
      " [-2.6039990e-07]]\n",
      "3000 0.6931472 [[-2.0713773e-07]\n",
      " [-2.0675552e-07]]\n",
      "3100 0.6931472 [[-1.5647359e-07]\n",
      " [-1.5609137e-07]]\n",
      "3200 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "3300 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "3400 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "3500 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "3600 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "3700 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "3800 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "3900 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "4000 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "4100 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "4200 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "4300 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "4400 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "4500 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "4600 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "4700 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "4800 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "4900 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "5000 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "5100 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "5200 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "5300 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "5400 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "5500 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "5600 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "5700 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "5800 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "5900 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "6000 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "6100 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "6200 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "6300 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "6400 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "6500 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "6600 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "6700 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "6800 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "6900 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "7000 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "7100 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "7200 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "7300 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "7400 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "7500 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "7600 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "7700 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "7800 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "7900 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "8000 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "8100 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "8200 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "8300 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "8400 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "8500 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "8600 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "8700 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "8800 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "8900 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "9000 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "9100 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "9200 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "9300 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "9400 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "9500 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "9600 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "9700 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "9800 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "9900 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "10000 0.6931472 [[-1.3263164e-07]\n",
      " [-1.3224943e-07]]\n",
      "Hypothesis: [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]  Correct: [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]  Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "predicted = tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1,10001):\n",
    "        _,cv,wv = sess.run([train,cost,w], feed_dict={x:xdata, y:ydata})\n",
    "        if step%100==0:\n",
    "            print(step, cv, wv)\n",
    "            \n",
    "    h, c, a = sess.run([hf, predicted, accuracy], feed_dict={x:xdata,y:ydata})\n",
    "    print(\"Hypothesis: {}  Correct: {}  Accuracy: {}\".format(h,c,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1235442\n",
      "500 0.69430554\n",
      "1000 0.69192374\n",
      "1500 0.68999267\n",
      "2000 0.68635404\n",
      "2500 0.67795885\n",
      "3000 0.6569146\n",
      "3500 0.61106646\n",
      "4000 0.55418247\n",
      "4500 0.495617\n",
      "5000 0.34796494\n",
      "5500 0.14574173\n",
      "6000 0.07349511\n",
      "6500 0.04673269\n",
      "7000 0.033701256\n",
      "7500 0.026159711\n",
      "8000 0.021291621\n",
      "8500 0.017908009\n",
      "9000 0.01542809\n",
      "9500 0.013536653\n",
      "10000 0.012048841\n",
      "Hypothesis: [[0.01485902 0.01466456]\n",
      " [0.99227667 0.9921706 ]\n",
      " [0.987723   0.98777306]\n",
      " [0.01317382 0.01301005]]  Correct: [[0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]]  Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 멀티레이어 퍼셉트론 기반 신경망\n",
    "x = tf.placeholder(tf.float32, shape=[None,2])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "# 히든 레이어\n",
    "w1 = tf.Variable(tf.random_normal([2,2]))\n",
    "b1 = tf.Variable(tf.random_normal([2]))\n",
    "layer1 = tf.sigmoid(tf.matmul(x, w1)+b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([2,2]))\n",
    "b2 = tf.Variable(tf.random_normal([2]))\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, w2)+b2)\n",
    "\n",
    "# 출력 레이어\n",
    "w3 = tf.Variable(tf.random_normal([2,2]))\n",
    "b3 = tf.Variable(tf.random_normal([1]))\n",
    "hf = tf.sigmoid(tf.matmul(layer2, w3)+b3)\n",
    "\n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        _,cv = sess.run([train,cost], feed_dict={x:xdata, y:ydata})\n",
    "        if step%500==0:\n",
    "            print(step, cv)\n",
    "            \n",
    "    h, p, a = sess.run([hf, predicted, accuracy], feed_dict={x:xdata,y:ydata})\n",
    "    print(\"Hypothesis: {}  Correct: {}  Accuracy: {}\".format(h,p,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 nan [784  10]\n",
      "1000 nan [784  10]\n",
      "1500 nan [784  10]\n",
      "2000 nan [784  10]\n",
      "2500 nan [784  10]\n",
      "3000 nan [784  10]\n",
      "3500 nan [784  10]\n",
      "4000 nan [784  10]\n",
      "4500 nan [784  10]\n",
      "5000 nan [784  10]\n",
      "5500 nan [784  10]\n",
      "6000 nan [784  10]\n",
      "6500 nan [784  10]\n",
      "7000 nan [784  10]\n",
      "7500 nan [784  10]\n",
      "8000 nan [784  10]\n",
      "8500 nan [784  10]\n",
      "9000 nan [784  10]\n",
      "9500 nan [784  10]\n",
      "10000 nan [784  10]\n",
      "Hypothesis: [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]  Correct: [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]  Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# wide & deep\n",
    "x = tf.placeholder(tf.float32, shape=[None,2])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "# 히든 레이어\n",
    "w1 = tf.Variable(tf.random_normal([2,2]))\n",
    "b1 = tf.Variable(tf.random_normal([2]))\n",
    "layer1 = tf.sigmoid(tf.matmul(x, w1)+b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([2,2]))\n",
    "b2 = tf.Variable(tf.random_normal([2]))\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, w2)+b2)\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([2,2]))\n",
    "b3 = tf.Variable(tf.random_normal([2]))\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, w3)+b3)\n",
    "\n",
    "w4 = tf.Variable(tf.random_normal([2,2]))\n",
    "b4 = tf.Variable(tf.random_normal([1]))\n",
    "hf = tf.sigmoid(tf.matmul(layer3, w3)+b3)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1,10001):\n",
    "        _,cv,wv = sess.run([train,cost,w], feed_dict={x:xdata, y:ydata})\n",
    "        if step%500==0:\n",
    "            print(step, cv, wv)\n",
    "            \n",
    "    h, p, a = sess.run([hf, predicted, accuracy], feed_dict={x:xdata,y:ydata})\n",
    "    print(\"Hypothesis: {}  Correct: {}  Accuracy: {}\".format(h,p,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow를 사용해서 MNIST 정확도 90%이상 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000,28*28).astype('float32')/255\n",
    "x_test = x_test.reshape(10000,28*28).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 10), (10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([784,128]))\n",
    "b1 = tf.Variable(tf.random_normal([128]))\n",
    "layer1 = tf.sigmoid(tf.matmul(x, w1)+b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([128, 64]))\n",
    "b2 = tf.Variable(tf.random_normal([64]))\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, w2)+b2)\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([64,10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hf = tf.nn.softmax(tf.matmul(layer2, w3)+b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf = tf.nn.softmax(tf.matmul(x,w)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(hf), axis=1))\n",
    "ls = 0.1\n",
    "train = tf.train.GradientDescentOptimizer(ls).minimize(cost)\n",
    "isCorrect = tf.equal(tf.argmax(hf,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(isCorrect, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "numEpoch = 100\n",
    "batchSize = 200\n",
    "numIter = x_train.shape[0]/batchSize\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(numEpoch):\n",
    "        avgCv = 0\n",
    "        for i in range(numIter):\n",
    "            batchX,batchY = mnist.train.next_batch(batchSize)\n",
    "            sess.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpoch = 100\n",
    "batchSize = 200\n",
    "numIter = x_train.shape[0]/batchSize\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(numEpoch):\n",
    "        avgCv = 0\n",
    "        for i in range(numIter):\n",
    "            batchX,batchY = mnist.train.next_batch(batchSize)\n",
    "            sess.run\n",
    "            \n",
    "            \n",
    "            avgCv = 0\n",
    "        for i in range(numIter): #\n",
    "            batchX,batchY = mnist.train.next_batch(batchSize) # ()안에 몇개씩 읽어올지(batchSize) 정해줄 수 있다\n",
    "            _,cv = sess.run([train, cost], feed_dict={x:batchX, y:batchY})\n",
    "            avgCv += cv/numIter\n",
    "        print(\"Epoch:{:04d}, cost:{:9f}\".format(epoch+1,avgCv))\n",
    "#         print(epoch+1, cv, avgCv)\n",
    "    print(\"정확도: \",accuracy.eval(session=sess, feed_dict={x:mnist.test.images, y:mnist.test.labels})) # test데이터로 확인\n",
    "    # mnist의 test데이터의 x는 mnist.test.image\n",
    "    # mnist의 test데이터의 y는 mnist.test.label\n",
    "    r = random.randint(0, mnist.test.num_examples-1)\n",
    "    print(\"lable: \", sess.run(tf.argmax(mnist.test.labels[r:r+1],1))) # r번째 이미지에 대한\n",
    "    print(\"predict: \",sess.run(tf.argmax(hf,1), feed_dict={x:mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28), cmap='Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Datasest/pima-indians-diabetes.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
